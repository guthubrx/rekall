# Audit de code — Rekall (sécurité, qualité, performance, production readiness)

- Date/heure de l’audit : 2025-12-13 17:16 CET
- Repository : https://github.com/guthubrx/rekall (déduit de `pyproject.toml:67`)
- Commit audité : `2f90dd0541f32be0d06bac2ae0d202ab79e7884b`
- Version applicative : `0.3.0` (`pyproject.toml:7`)
- Environnement d’audit : macOS (darwin), Python 3.12.12, uv 0.9.16

## 1) Résumé exécutif

### Score global
- Score global : **D** (non “prod-ready” en l’état)

### Scores par catégorie (A→F)
- Sécurité & données : **C-**
- Qualité & maintenabilité : **D**
- Architecture : **C-**
- Tests : **D**
- Performance : **B-**
- Fiabilité / Robustesse : **C**
- Observabilité / SRE : **C**
- Release engineering : **C**
- Gouvernance : **C+**
- Conformité / privacy : **C**
- Supply chain : **C**
- Coût / efficience : **B**

### Top 5 à corriger immédiatement
1. **SSRF / accès réseaux internes** via la chaîne `sources inbox add` → `staging enrich` (validation URL incomplète + fetch non borné).
2. **Durcissement import/export archives** : protections anti zip-bomb/oversize non appliquées malgré des constantes dédiées.
3. **CI/CD cassé** : `uv sync --dev` n’installe pas les extras `dev`, `pip-audit --strict` échoue sur le package editable, ruff/format + tests ne passent pas.
4. **Hygiène qualité** : `ruff check` et `ruff format --check` échouent (beaucoup de fichiers), dettes de style + imports/unused.
5. **Perf/lock contention SQLite** : commits par résultat en tracking d’accès + absence de `busy_timeout` → risque de “database is locked” et latence.

### Dette technique
- Niveau : **élevée** (gros monolithes, qualité gate non vert, incohérences docs/config, tests instables)

### Synthèse SLO / budgets (proposés)
Contexte : application **CLI/TUI locale** + **serveur MCP** en stdio (pas un service réseau HTTP “prod”).

SLO par défaut (si non explicités) :
- CLI `rekall version` : p95 < **400 ms** (cold), p95 < **250 ms** (warm).
  - Mesure observée (sur machine d’audit, DB vierge) : ~0.29s cold, ~0.23–0.24s warm.
- CLI `rekall search` (DB 100k entrées, FTS uniquement) : p95 < **250 ms**, p99 < **800 ms**.
- TUI : boucle UI réactive (aucun handler > **50 ms** hors I/O), pas de freeze perceptible.
- Mémoire :
  - Mode sans embeddings : RSS < **150 MB**
  - Mode embeddings : RSS < **1.5 GB** (modèle + numpy/torch selon stack), avec **unload** après inactivité.
- I/O / DB :
  - Pas plus de **1 commit** par commande “read-heavy” (sauf explicitement demandé), WAL activé.
- Budget coût (ordre de grandeur) :
  - 0 € infra (local), coût principal = temps CPU/IO et éventuellement téléchargement de modèles (embeddings).

### Hotspots (churn + taille)
Hotspots par churn (approx. via `git log --name-only`):
- `README.md` (13), `rekall/tui_main.py` (10), `rekall/db.py` (9), `rekall/tui.py` (8), `rekall/models.py` (8).

Hotspots par taille (LOC) :
- `rekall/tui_main.py` (~11758 lignes), `rekall/cli_main.py` (~4876), `rekall/db.py` (~4547).

## 2) Contexte & périmètre

- Langage principal : **Python** (133 fichiers `.py` trackés), + un peu de shell (`.sh`) et YAML (CI).
- Type d’application : **CLI + TUI** (Textual) + **MCP server** (outillage agent), stockage local SQLite/FTS5.
- Environnements cibles : macOS/Linux/Windows, Python >= 3.10 (`pyproject.toml:11`).
- Dépendances externes :
  - SQLite local (stdlib)
  - HTTP sortant : `httpx` (enrichissement), stdlib `http.client` (link rot)
  - Modèles embeddings (optionnel) : `sentence-transformers`, `numpy` (`pyproject.toml:55-58`)

## 3) Threat model léger

### Assets (à protéger)
- Base SQLite `knowledge.db` (contenu potentiellement sensible : snippets, URLs internes, PII, tokens accidentels).
- Fichiers de config et d’intégration (chemins, préférences, potentiellement contextes).
- Historique/imports de transcripts (peut contenir données confidentielles).

### Acteurs/menaces
- Attaquant “contenu” : prompt injection / contenu web influençant l’agent/outil (ex: WebFetch) → capture d’URL malveillantes.
- Attaquant local : accès multi-utilisateurs à la machine, malware, ou collègue via partage de `.rekall/`.
- Supply chain : dépendances Python/artefacts modèles.

### Surfaces d’attaque principales
- Pipeline Sources : `rekall sources inbox add` (hook) → `staging enrich` (fetch HTTP) → stockage.
- Import/export `.rekall.zip` (fichiers non fiables).
- MCP tools : ajout d’entrées, auto-capture, auto-détection git, vérification de sources (fetch).

### Scénarios dominants (exemples)
- SSRF local : URL vers `169.254.169.254` / services intranet capturée via hook puis “enrich” la requête.
- DoS zip-bomb : import d’une archive énorme/compressée qui explose la mémoire/disque.
- Fuite de secrets : partage “team” de `knowledge.db` dans git.

## 4) Findings critiques — Sécurité & données

### [CRITIQUE] SSRF / accès à ressources internes via `sources inbox add` → `staging enrich`

- Catégorie : SSRF / validation entrées / réseau sortant
- Fichier(s) :
  - `rekall/cli_main.py:3590` (validation URL “simple”)
  - `rekall/enrichment.py:161` (fetch HTTP sans garde-fous SSRF)
- Description :
  - `rekall sources inbox add` (utilisé par hook) valide très partiellement l’URL : blocage incomplet des plages privées, pas de résolution DNS, pas de filtrage IPv6, et utilisation de `netloc` au lieu de `hostname`.
  - `staging enrich` déclenche ensuite un `GET` HTTP sur l’URL (redirects activés) sans limite de taille/réseau interne.
- Impact :
  - Lecture de endpoints sensibles accessibles depuis la machine (metadata cloud, admin panels, services intranet), stockage du résultat (title/description) et potentiellement exfiltration via export/partage.
- Preuve :
  - Validation actuelle :
    - `rekall/cli_main.py:3594-3603` : ne bloque pas `169.254.169.254`, `172.17.x`, IPv6 ULA/link-local, ni “DNS rebinding”.
  - Fetch :
    - `rekall/enrichment.py:191-197` : `httpx.AsyncClient(follow_redirects=True)` puis `response = await client.get(url)`.
- Remédiation (recommandée) :
  1. Centraliser la validation URL (une seule source de vérité) et **réutiliser** la logique SSRF déjà présente côté connecteurs (`rekall/connectors/base.py:134`), en l’adaptant au cas “inbox add”.
  2. Bloquer par défaut :
     - IPs privées/réservées (IPv4/IPv6), `localhost`, link-local, `0.0.0.0`, metadata cloud (ex: `169.254.169.254`).
     - Schémas non HTTP(S), userinfo, ports non standards si besoin.
     - Redirects vers des hosts interdits (valider chaque hop).
  3. Ajouter des **bornes** sur le fetch : taille max (ex 1–2MB), type contenu (text/html), nombre max de redirects, timeouts distincts (connect/read).
  4. Prévoir un mécanisme “allowlist/denylist” configurable (ex: `config.toml`) + mode “unsafe” explicite.
- Exemple (esquisse) :
  - Remplacer `validate_url_simple` par un validateur commun basé sur `urllib.parse.urlparse().hostname` + DNS resolve + check IP ranges.
- Vérification :
  - Tests unitaires : URLs vers `127.0.0.1`, `169.254.169.254`, `http://[::1]/`, `https://localhost@evil.com` (userinfo bypass) doivent être **quarantined**.
  - E2E : `rekall sources inbox add http://169.254.169.254/latest/meta-data/` → `is_valid=false` et pas d’enrichissement.
- Effort estimé : **M** (1–2 jours, avec tests)
- Risque de régression : **moyen** (risque de faux positifs sur URLs légitimes) ; mitigation : allowlist + logs de quarantine.
- Références :
  - OWASP SSRF Prevention Cheat Sheet
  - CWE-918 (SSRF), OWASP A10 (SSRF souvent classé sous misconfig/SSRF selon contexte)

### [HAUTE] Partage “team” : DB non exclue par défaut dans `.rekall/` (risque fuite secrets/PII)

- Catégorie : secrets/PII, gouvernance, data protection
- Fichier(s) :
  - `rekall/paths.py:400` (paramètre `exclude_db_from_git=False`)
  - `rekall/cli_main.py:346` (message incitant à ajouter `.rekall/` à Git)
- Description :
  - `init_local_project(... exclude_db_from_git: bool = False)` génère un `.gitignore` où `knowledge.db` n’est **pas** ignorée par défaut (`rekall/paths.py:428-437`).
  - La CLI suggère explicitement d’ajouter `.rekall/` à Git (`rekall/cli_main.py:376`).
- Impact :
  - Risque élevé de commit involontaire de données sensibles (snippets, tokens accidentels, URLs internes, PII) dans un repo partagé/public.
- Preuve :
  - `rekall/paths.py:405-437` + `rekall/cli_main.py:376`.
- Remédiation :
  - Inverser le défaut : `exclude_db_from_git=True` par défaut, et forcer un flag explicite `--share-db` si l’utilisateur veut versionner.
  - Ajouter un “danger banner” dans la CLI/TUI : “attention, la DB peut contenir des secrets/PII”.
  - Recommander un partage via export `.rekall.zip` filtré/sanitisé plutôt que la DB brute.
- Vérification :
  - `rekall init --local` crée `.rekall/.gitignore` avec `knowledge.db` ignoré.
- Effort : **S** (quelques heures)
- Risque de régression : **faible** (changement comportement par défaut ; mitigation : message clair + option explicite).
- Références : CWE-200 (Information Exposure), OWASP “Sensitive Data Exposure” (historique)

### [HAUTE] Durcissement archives : protections anti zip-bomb/oversize non appliquées

- Catégorie : durcissement parsers/archives, disponibilité
- Fichier(s) :
  - `rekall/archive.py:148` (création zip)
  - `rekall/archive.py:182` (validation)
  - `rekall/archive.py:228` et `rekall/archive.py:261` (lecture intégrale de `entries.json`)
  - `rekall/constants.py:18` (limites définies mais non utilisées)
- Description :
  - Le code lit `entries.json` en mémoire (`ZipFile.read`) sans vérifier `file_size`, ratio de compression, taille totale décompressée, ni nombre d’entrées.
  - Des constantes existent pour ces contrôles (`MAX_ARCHIVE_SIZE`, `MAX_DECOMPRESSED_SIZE`, `MAX_COMPRESSION_RATIO`) mais ne sont pas appliquées.
- Impact :
  - DoS mémoire/disque, crash, ralentissements sévères, potentiel blocage machine si import d’archive malveillante.
- Preuve :
  - `rekall/archive.py:228` et `rekall/archive.py:261` + `rekall/constants.py:18-21`.
- Remédiation :
  - Avant toute lecture :
    - refuser archive si taille > `MAX_ARCHIVE_SIZE`
    - pour chaque fichier : vérifier `ZipInfo.file_size`, `compress_size`, ratio et somme des tailles
    - refuser si ratio > `MAX_COMPRESSION_RATIO` ou total > `MAX_DECOMPRESSED_SIZE`
  - Ajouter validation JSON/Entry (pydantic) lors d’import.
  - Optionnel : signature (authenticité) si échanges inter-équipes.
- Vérification :
  - Tests : archive artificielle avec ratio extrême doit être rejetée avec message clair.
- Effort : **M**
- Risque de régression : **faible à moyen** (archives légitimes très grosses) ; mitigation : option `--unsafe-max-size`.
- Références : CWE-409 (Resource Exhaustion), OWASP “Zip Slip/Zip bomb” (DoS)

## 5) Findings performance & efficience (CPU/Mémoire/I/O/Startup)

### [MOYENNE] SQLite : commits par résultat en tracking d’accès + N+1 tags

- Catégorie : perf DB / contention / latence
- Fichier(s) :
  - `rekall/db.py:910` (commit à chaque `_update_access_tracking`)
  - `rekall/db.py:897` (requêtes tags par entrée)
- Métrique(s) impactée(s) :
  - Latence p95/p99 de `search`, contention SQLite, I/O sync, batterie.
- Description :
  - `search()` appelle `_update_access_tracking()` par entrée et commit à chaque fois (`rekall/db.py:949`), ce qui peut créer N commits pour N résultats.
  - La récupération des tags utilise une requête par entrée (N+1) (`rekall/db.py:898-902`).
- Gain attendu :
  - Réduction latence et lock contention (ordre de grandeur : 2× à 10× sur recherches multi-résultats).
- Trade-offs :
  - Complexité légère (batch updates), nécessite tests sur concurrence.
- Remédiation :
  - Accumuler les IDs vus et faire :
    - une seule transaction pour updates (commit 1×)
    - update SQL du type `access_count = access_count + 1` + update `last_accessed`
  - Pour tags : requête groupée via `GROUP_CONCAT` et mapping.
  - Ajouter `PRAGMA busy_timeout` (ex 3000–5000ms) pour réduire erreurs “database is locked”.
- Validation :
  - Bench reproductible : 100k entrées, `search(limit=20)` x100, comparer p95/p99 avant/après.
- Plan de rollback :
  - Feature flag `update_access` par défaut, ou fallback “commit-per-entry”.
- Effort : **M**
- Risque de régression : **moyen** (sémantique access_count) ; mitigation : tests unitaires sur consolidation.

### [BASSE] Enrichissement web : pas de limite de taille/Content-Type, lecture `response.text`

- Catégorie : perf réseau/mémoire
- Fichier(s) : `rekall/enrichment.py:191`
- Métrique(s) impactée(s) : latence batch, RSS, I/O réseau
- Description :
  - `response.text` charge tout le body en mémoire (`rekall/enrichment.py:205`) ; pas de cap.
- Remédiation :
  - Stream + limite (ex: lire max 1–2MB), vérifier `Content-Type` text/html.
- Validation : test sur gros payload + garantir temps max par URL.
- Rollback : garder mode actuel derrière option.
- Effort : **S**
- Risque : **faible**

## 6) Findings fiabilité & production-readiness

### [HAUTE] CI/CD non fiable : mauvais flags uv, lint/format/test non verts, pip-audit strict cassant

- Catégorie : CI/CD, qualité gate, supply chain
- Fichier(s) :
  - `/.github/workflows/ci.yml:25` (install deps)
  - `/.github/workflows/ci.yml:58` (pip-audit strict)
  - `pyproject.toml:45` (dev deps déclarées en extras)
- Description :
  - `uv sync --frozen --dev` (CI) n’installe pas les extras `dev` (pytest/ruff/bandit/pip-audit).
  - `pip-audit --strict` échoue sur le package `rekall` installé en editable (non auditable PyPI).
  - `ruff check` et `ruff format --check` échouent actuellement (nombreux fichiers).
  - Les tests requièrent au minimum `numpy` et `pytest-asyncio` mais ces dépendances ne sont pas garanties par l’environnement CI.
- Impact :
  - Absence de quality gate : PRs peuvent passer sans lints/tests réels, ou CI rouge en permanence.
  - Risque de régressions et vulnérabilités non détectées.
- Preuve :
  - CI : `/.github/workflows/ci.yml:26-31`, `/.github/workflows/ci.yml:57-60`.
  - Dépendances : `pyproject.toml:45-58`.
- Remédiation :
  - Remplacer `uv sync --frozen --dev` par `uv sync --frozen --extra dev` (+ `--extra embeddings` si tests en dépendent).
  - Pour `pip-audit` :
    - retirer `--strict` ou ajouter un mode qui n’échoue pas sur “editable”, et/ou auditer un export `requirements.txt` généré depuis `uv.lock`.
  - Ajouter `pytest-asyncio` à l’extra `dev` (ou migrer les tests async sur anyio sans mark asyncio).
  - Stabiliser tests (isolation REKALL_HOME temp) + rendre les tests embeddings conditionnels aux extras.
  - Exiger `ruff format` (auto) + “fix lint” pour repasser vert.
- Vérification :
  - CI vert sur matrice 3.10–3.13, lint + format + tests + audit deps.
- Effort : **M** (1–3 jours selon stabilisation tests)
- Risque de régression : **faible** (CI uniquement) ; mitigation : rollout par PR.

### [MOYENNE] Incohérences paths / backups : legacy `~/.rekall/backups` malgré XDG

- Catégorie : exploitabilité / cohérence config
- Fichier(s) : `rekall/backup.py:84`
- Description :
  - Les chemins de données sont XDG (`rekall/paths.py:311-316`), mais les backups vont dans `~/.rekall/backups` (`rekall/backup.py:90-92`).
- Impact :
  - Surprise utilisateur, dispersion des données, risque de permissions de dossier trop permissives.
- Remédiation :
  - Utiliser `get_config().paths.data_dir / "backups"` et appliquer `DIR_PERMISSIONS`.
- Vérification :
  - `rekall backup` crée backups sous XDG data dir.
- Effort : **S**
- Risque : **faible**

## 7) CI/CD, supply chain, release

- Points positifs :
  - `uv.lock` présent (pinning), `ruff` et `gitleaks` intégrés en CI.
  - `CHANGELOG.md` suit SemVer/Keep a Changelog.
- Problèmes :
  - CI `uv sync --dev` (voir finding) + `pip-audit --strict` (cassant).
  - `pip-audit` ne reconnaît pas `uv.lock` directement : prévoir un export SBOM CycloneDX ou requirements lock.

## 8) Observabilité / SRE (adapté CLI/MCP)

- Constats :
  - Logs via `logging` présents mais pas de stratégie de configuration (niveau, format, destinations).
  - Pas d’audit logs métier (ex: “entry added/modified/deleted”), utile en contexte MCP/agents.
- Recommandations :
  - Ajouter un mode `--log-level` et logs structurés (JSON optionnel) pour `rekall mcp`.
  - Ajouter des événements “audit” (sans contenu sensible) : id, action, timestamp, source (cli/mcp/tui).
  - Ajouter “privacy by default” : éviter logs contenant content/context.

## 9) Architecture & organisation

- Constats :
  - Gros monolithes (`rekall/tui_main.py`, `rekall/cli_main.py`, `rekall/db.py`) → coût de changement élevé.
  - Présence d’un plan de modularisation (package `rekall/cli/`), mais des modules restent “placeholder” (`rekall/cli/import_export.py`).
  - Incohérences de constantes non utilisées (`rekall/constants.py`) et docs (SECURITY.md).
- Recommandations :
  - Continuer extraction progressive : `cli_main.py` → sous-modules (core, entries, sources, system…).
  - Ajouter des “contracts” internes (schemas JSON pour sorties `--json`, versionnés).
  - Nettoyer/aligner `rekall/constants.py` avec les vraies paths/limites, ou supprimer si obsolète.

## 10) Hygiène & contributions IA

- Signal :
  - Nombreux commits “Co-Authored-By: Claude …” (ex: dernier commit) → forte contribution IA.
- Risques :
  - Incohérences (ex: CI flags uv, tests dépendances), code verbeux, gestion d’erreurs silencieuse.
- Actions :
  - Exiger PR template avec : tests pass, ruff format/check, revue humaine sur zones sécurité (URL fetch, import/export, mcp tools).
  - Documenter conventions : “no bare except”, “no silent pass”, “validate external inputs”.

## 11) Métriques détaillées (observées)

- Taille repo (tracké) : 354 fichiers (`git ls-files | wc -l`)
- Python : 133 fichiers
- Tests :
  - Collecte : 777 tests
  - Statut (sur machine d’audit) : échecs significatifs (exécution avec numpy : 41 failed / 734 passed / 2 skipped)
  - Remarque : présence de tests async mais absence de `pytest-asyncio` en extra dev → warnings et instabilité.
- Lint/format :
  - `ruff check .` : KO (nombreux I001/F401/UP0xx…)
  - `ruff format --check` : 51 fichiers à reformater
- SAST (bandit) :
  - 67 findings (9 medium, 58 low) ; beaucoup liés à `try/except pass` et SQL dynamique contrôlé.
- Scan secrets (rg heuristique) : aucun match évident.
- Performance startup :
  - `rekall version` : ~0.29s cold / ~0.23–0.24s warm (DB vierge, `REKALL_HOME` temp).

## 12) Dépendances vulnérables

Résultat `pip-audit --desc on --skip-editable` (env d’audit) :
- Aucune vulnérabilité connue détectée.
- Note : `pip-audit --strict` échoue sur le package local editable (à corriger en CI).

| Dépendance | Version actuelle | CVE | Sévérité | Version recommandée |
|---|---:|---|---|---|
| (aucune détectée) | | | | |

## 13) Points positifs

- Verrouillage deps via `uv.lock`, CI avec gitleaks, ruff et tests (intention claire).
- Durcissement partiel : permissions fichier DB (`rekall/db.py:463-469`), SSRF hardening robuste côté connecteurs (`rekall/connectors/base.py`).
- Documentation riche + changelog.

## 14) Roadmap de remédiation (priorisée)

1) Immédiat (< 1 semaine)
- Corriger SSRF : validation URL unifiée + bornes fetch + tests.
- Durcir archives : appliquer limites, rejeter zip-bombs, valider entrées.
- Réparer CI : `uv sync --extra dev`, ajuster pip-audit, stabiliser tests minimaux, ruff format.

2) Court terme (< 1 mois)
- Stabiliser suite de tests + isolation (REKALL_HOME temp), ajouter `pytest-asyncio` ou migration anyio.
- Réduire monolithes (extraire “sources” et “mcp” en modules).
- Améliorer SQLite : busy_timeout, batch commits, optimisation tags.

3) Moyen terme (< 3 mois)
- Gouvernance : CODEOWNERS + règles de review, checklist sécurité pour PR.
- Observabilité : logs structurés optionnels, audit logs.
- Conformité/privacy : stratégie de rétention, redaction export, option chiffrement (SQLCipher/OS keychain).

4) Long terme
- Bench/perf gating : budgets perf, benchs reproductibles.
- Signatures d’archives si usage inter-équipes.
- Modularisation complète CLI/TUI + stabilité des contrats JSON.

## 15) Couverture de checklist (synthèse)

- A Sécurité & données : SSRF, permissions, secrets scanning, archives, supply chain.
- B Qualité/maintenabilité : ruff/vulture, monolithes, cohérence constants/docs.
- C Fiabilité prod : CI cassé, SQLite contention, migrations.
- D Observabilité : logging & audit logs (recommandations).
- E Tests/données : tests instables + dépendances manquantes, intégrité DB.
- F Performance : commits DB, N+1 queries, fetch non borné.
- G Release : changelog, mais pipeline à réparer.
- H Gouvernance : bus factor 1, pas de CODEOWNERS.
- I Contrats : JSON output existe, pas versionné.
- J UX/i18n : TUI riche, mais i18n partielle et tests UI instables.
- K Coût : embeddings lourds, budgets proposés.
- L Hygiène IA : commits co-author Claude, recommandations de garde-fous.

