# üìã Plan de Rem√©diation Audit S√©curit√© - Rekall

**Date:** 2025-12-11
**Score initial:** B- (S√©curit√© C, Qualit√© B, Architecture B, Tests B-, Performance B)
**Objectif:** Atteindre un niveau SOTA (State of the Art) sur chaque dimension

---

## üìö Table des Mati√®res

### S√©curit√© et Qualit√©
1. [CI/CD et Scans de S√©curit√©](#1-cicd-et-scans-de-s√©curit√©)
2. [Chiffrement des Donn√©es SQLite](#2-chiffrement-des-donn√©es-sqlite)
3. [Authentification et Autorisation](#3-authentification-et-autorisation)
4. [Gestion des PII et Conformit√© RGPD](#4-gestion-des-pii-et-conformit√©-rgpd)
5. [Validation des Entr√©es Utilisateur](#5-validation-des-entr√©es-utilisateur)
6. [Verrouillage des D√©pendances](#6-verrouillage-des-d√©pendances)
7. [Qualit√© de Code et Linting](#7-qualit√©-de-code-et-linting)
8. [Architecture et S√©paration des Couches](#8-architecture-et-s√©paration-des-couches)

### Coh√©rence et Maintenabilit√©
9. [Duplication de Code et Principe DRY](#9-duplication-de-code-et-principe-dry)
10. [CLI Monolithique et Modularisation](#10-cli-monolithique-et-modularisation)
11. [Code Mort et Int√©grations Non Raccord√©es](#11-code-mort-et-int√©grations-non-raccord√©es)

### Robustesse et Observabilit√©
12. [Observabilit√© et Gestion d'Erreurs](#12-observabilit√©-et-gestion-derreurs)
13. [Persistance de Configuration](#13-persistance-de-configuration)
14. [Durcissement des Archives et Imports](#14-durcissement-des-archives-et-imports)

### Hygi√®ne du Code G√©n√©r√© par IA (Nouveau)
15. [D√©tection et Correction des Contributions IA](#15-d√©tection-et-correction-des-contributions-ia)

### Synth√®se
16. [Roadmap de Mise en ≈íuvre](#16-roadmap-de-mise-en-≈ìuvre)

---

## üéØ Analyse de Pertinence par Niveau

### Contexte Rekall

Avant d'√©valuer chaque niveau, rappelons le contexte sp√©cifique de Rekall :

| Caract√©ristique | Impact sur les choix |
|-----------------|---------------------|
| **CLI Python locale** | Pas d'exposition r√©seau ‚Üí moins de surface d'attaque |
| **Usage personnel** | Pas de multi-utilisateurs ‚Üí authentification moins critique |
| **Base de connaissances** | Donn√©es potentiellement sensibles mais pas critiques (pas de secrets bancaires) |
| **Projet open-source** | Qualit√© de code importante pour contributions |
| **< 500 LOC** | Architecture simple suffisante |

### L√©gende des √âvaluations

| Badge | Signification |
|-------|---------------|
| ‚úÖ **ESSENTIEL** | ROI excellent, effort minimal, impact maximal. √Ä faire absolument. |
| üëç **RECOMMAND√â** | Bon rapport effort/b√©n√©fice. Am√©liore significativement le projet. |
| üü° **OPTIONNEL** | Utile dans certains contextes. √Ä consid√©rer selon les besoins r√©els. |
| ‚ö†Ô∏è **OVERKILL** | Over-engineering pour ce contexte. Complexit√© injustifi√©e. |

---

### üìä Tableau R√©capitulatif

#### S√©curit√© et Qualit√© (Sections 1-8)

| Section | Niveau 1 | Niveau 2 | Niveau 3 | Recommandation |
|---------|----------|----------|----------|----------------|
| **1. CI/CD & S√©curit√©** | ‚úÖ ESSENTIEL | üëç RECOMMAND√â | ‚ö†Ô∏è OVERKILL | Niveaux 1-2 |
| **2. Chiffrement SQLite** | ‚úÖ ESSENTIEL | üü° OPTIONNEL | ‚ö†Ô∏è OVERKILL | Niveau 1 obligatoire |
| **3. Authentification** | üü° OPTIONNEL | ‚ö†Ô∏è OVERKILL | ‚ö†Ô∏è OVERKILL | Si chiffrement activ√© |
| **4. RGPD/PII** | üëç RECOMMAND√â | üü° OPTIONNEL | ‚ö†Ô∏è OVERKILL | Niveau 1 suffit |
| **5. Validation entr√©es** | ‚úÖ ESSENTIEL | üëç RECOMMAND√â | ‚ö†Ô∏è OVERKILL | Niveaux 1-2 |
| **6. Verrouillage deps** | ‚úÖ ESSENTIEL | üëç RECOMMAND√â | üü° OPTIONNEL | Niveaux 1-2 |
| **7. Linting** | ‚úÖ ESSENTIEL | üëç RECOMMAND√â | üü° OPTIONNEL | Niveaux 1-2 |
| **8. Architecture** | üëç RECOMMAND√â | ‚ö†Ô∏è OVERKILL | ‚ö†Ô∏è OVERKILL | Niveau 1 max |

#### Coh√©rence et Maintenabilit√© (Sections 9-11)

| Section | Niveau 1 | Niveau 2 | Niveau 3 | Recommandation |
|---------|----------|----------|----------|----------------|
| **9. Duplication (DRY)** | ‚úÖ ESSENTIEL | üëç RECOMMAND√â | ‚ö†Ô∏è OVERKILL | Niveaux 1-2 |
| **10. CLI Modulaire** | üëç RECOMMAND√â | üü° OPTIONNEL | ‚ö†Ô∏è OVERKILL | Niveau 1 suffit |
| **11. Code Mort** | ‚úÖ ESSENTIEL | üëç RECOMMAND√â | üü° OPTIONNEL | Niveaux 1-2 |

#### Robustesse et Observabilit√© (Sections 12-14)

| Section | Niveau 1 | Niveau 2 | Niveau 3 | Recommandation |
|---------|----------|----------|----------|----------------|
| **12. Gestion Erreurs** | ‚úÖ ESSENTIEL | üëç RECOMMAND√â | üü° OPTIONNEL | Niveaux 1-2 |
| **13. Config Atomique** | ‚úÖ ESSENTIEL | üëç RECOMMAND√â | ‚ö†Ô∏è OVERKILL | Niveau 1-2 |
| **14. S√©curit√© Archives** | ‚úÖ ESSENTIEL | üëç RECOMMAND√â | üü° OPTIONNEL | Niveaux 1-2 |

#### Hygi√®ne du Code IA (Section 15 - Nouveau)

| Section | Niveau 1 | Niveau 2 | Niveau 3 | Recommandation |
|---------|----------|----------|----------|----------------|
| **15. Contributions IA** | ‚úÖ ESSENTIEL | üëç RECOMMAND√â | üü° OPTIONNEL | Niveaux 1-2 |

---

### üîç Analyse D√©taill√©e par Section

#### 1. CI/CD et Scans de S√©curit√©

| Niveau | √âvaluation | Justification |
|--------|------------|---------------|
| **Niveau 1** (pip-audit + Bandit) | ‚úÖ ESSENTIEL | Effort minimal (~30 min), d√©tecte les CVE dans les d√©pendances. Indispensable pour tout projet Python moderne. |
| **Niveau 2** (Safety + TruffleHog) | üëç RECOMMAND√â | Safety ajoute une couverture CVE compl√©mentaire. TruffleHog utile si tu commites des configs avec secrets potentiels. |
| **Niveau 3** (Semgrep + SARIF) | ‚ö†Ô∏è OVERKILL | Semgrep et l'int√©gration GitHub Security Tab sont des outils enterprise. Pour une CLI personnelle de <500 LOC, c'est de l'artillerie lourde. Bandit suffit largement. |

**üí° Verdict:** Impl√©menter Niveaux 1-2. Le Niveau 3 n'apporte rien de tangible.

---

#### 2. Chiffrement des Donn√©es SQLite

| Niveau | √âvaluation | Justification |
|--------|------------|---------------|
| **Niveau 1** (Permissions 600) | ‚úÖ ESSENTIEL | 3 lignes de code, z√©ro d√©pendance, protection imm√©diate contre les lectures accidentelles. Aucune raison de ne pas le faire. |
| **Niveau 2** (SQLCipher optionnel) | üü° OPTIONNEL | Ajoute une d√©pendance native (compilation possible), complexifie le setup. Utile **uniquement si** tu stockes des donn√©es vraiment sensibles (mots de passe, secrets API). Pour des notes de dev classiques ? Pas n√©cessaire. |
| **Niveau 3** (Migration auto) | ‚ö†Ô∏è OVERKILL | M√©canisme de migration automatique chiffr√©‚Üínon-chiffr√© avec backup s√©curis√© ? C'est de l'over-engineering. Si tu veux chiffrer, tu chiffres d√®s le d√©part. |

**üí° Verdict:** Niveau 1 obligatoire. Niveau 2 seulement si tu stockes des secrets r√©els.

---

#### 3. Authentification et Autorisation

| Niveau | √âvaluation | Justification |
|--------|------------|---------------|
| **Niveau 1** (Keyring passphrase) | üü° OPTIONNEL | Utile **uniquement si** le chiffrement SQLCipher est activ√© (pour stocker la passphrase). Sinon, aucune valeur ajout√©e - c'est d√©j√† TON shell, TES fichiers, TON user Unix. |
| **Niveau 2** (Sessions avec timeout) | ‚ö†Ô∏è OVERKILL | Des sessions avec timeout d'inactivit√© pour une CLI ? Tu tapes une commande, elle s'ex√©cute, fin. Il n'y a pas de "session" persistante √† prot√©ger. Pattern copi√© des apps web, non applicable ici. |
| **Niveau 3** (Audit logs) | ‚ö†Ô∏è OVERKILL | Logger chaque acc√®s √† tes propres notes ? C'est du paranoia-driven development. Les logs syst√®me (`.bash_history`) suffisent pour l'audit personnel. |

**üí° Verdict:** Impl√©menter Niveau 1 **seulement si** SQLCipher activ√©. Sinon, skip complet.

---

#### 4. Gestion des PII et Conformit√© RGPD

| Niveau | √âvaluation | Justification |
|--------|------------|---------------|
| **Niveau 1** (Classification + doc) | üëç RECOMMAND√â | Ajouter un champ `classification` et documenter la politique de donn√©es prend 30 min et montre une maturit√© du projet. Utile pour les contributeurs. |
| **Niveau 2** (D√©tection PII regex) | üü° OPTIONNEL | Les regex basiques (email, t√©l√©phone) sont faciles √† ajouter. Mais utiliser un mod√®le ML (DeBERTa-v3) pour d√©tecter les PII dans une CLI locale ? Overkill absolu. Reste sur les regex simples si tu le fais. |
| **Niveau 3** (Purge automatique) | ‚ö†Ô∏è OVERKILL | `secure_delete` avec √©crasement m√©moire et `VACUUM` ? Tu n'es pas une banque. Un simple `DELETE` SQLite suffit. La "r√©cup√©ration forensique" de notes personnelles n'est pas un threat model r√©aliste. |

**üí° Verdict:** Niveau 1 pour la doc et la structure. Niveau 2 regex seulement si besoin r√©el.

---

#### 5. Validation des Entr√©es Utilisateur

| Niveau | √âvaluation | Justification |
|--------|------------|---------------|
| **Niveau 1** (Pydantic validators) | ‚úÖ ESSENTIEL | Pydantic est d√©j√† quasi-standard en Python moderne. Validation propre, messages d'erreur clairs, typage fort. Excellent ROI. |
| **Niveau 2** (Requ√™tes param√©tr√©es strictes) | üëç RECOMMAND√â | Tu utilises probablement d√©j√† des `?` placeholders. Formaliser √ßa avec une couche de validation FTS est une bonne pratique d√©fensive. |
| **Niveau 3** (Triggers SQL audit) | ‚ö†Ô∏è OVERKILL | Des triggers SQLite pour logger chaque INSERT/UPDATE dans une table d'audit ? Pour une CLI personnelle ? C'est du pattern enterprise copi√© sans r√©flexion. Complexit√© inutile, performance d√©grad√©e, maintenance accrue. |

**üí° Verdict:** Niveaux 1-2 recommand√©s. Niveau 3 √† √©viter.

---

#### 6. Verrouillage des D√©pendances

| Niveau | √âvaluation | Justification |
|--------|------------|---------------|
| **Niveau 1** (uv lock) | ‚úÖ ESSENTIEL | `uv lock` prend 5 secondes, garantit la reproductibilit√©. Aucune raison de ne pas le faire. C'est le standard 2025. |
| **Niveau 2** (CI avec --frozen) | üëç RECOMMAND√â | V√©rifier en CI que le lockfile est synchronis√© √©vite les "√ßa marche sur ma machine". Bonne pratique √† faible co√ªt. |
| **Niveau 3** (Hash verification) | üü° OPTIONNEL | `--require-hashes` et `no-binary` pour compiler les packages ? Pour un projet open-source personnel, c'est excessif. R√©serve √ßa aux environnements haute s√©curit√© (banque, sant√©). |

**üí° Verdict:** Niveaux 1-2 obligatoires. Niveau 3 optionnel.

---

#### 7. Qualit√© de Code et Linting

| Niveau | √âvaluation | Justification |
|--------|------------|---------------|
| **Niveau 1** (Ruff E, F, W) | ‚úÖ ESSENTIEL | Configuration de base en 2 min. D√©tecte les erreurs √©videntes. Aucune raison de s'en passer. |
| **Niveau 2** (R√®gles √©tendues + S) | üëç RECOMMAND√â | Ajouter isort, bugbear, et les r√®gles Bandit dans Ruff (S) am√©liore la qualit√© sans friction. |
| **Niveau 3** (Pre-commit hooks) | üü° OPTIONNEL | Les pre-commit hooks sont nice-to-have mais pas critiques pour un d√©veloppeur solo. La CI fait le m√™me travail. Utile si plusieurs contributeurs. |

**üí° Verdict:** Niveaux 1-2 recommand√©s. Niveau 3 si contributions externes.

---

#### 8. Architecture et S√©paration des Couches

| Niveau | √âvaluation | Justification |
|--------|------------|---------------|
| **Niveau 1** (Entit√©s extraites) | üëç RECOMMAND√â | S√©parer les dataclasses m√©tier dans `entities.py` am√©liore la lisibilit√© et la testabilit√©. Effort minimal, gain de clart√©. |
| **Niveau 2** (Repository Pattern) | ‚ö†Ô∏è OVERKILL | Pour un projet de <500 LOC avec un seul backend (SQLite), cr√©er des interfaces abstraites `NoteRepository` + impl√©mentation concr√®te est de l'over-abstraction. Tu n'auras jamais de backend PostgreSQL ou MongoDB. YAGNI (You Ain't Gonna Need It). |
| **Niveau 3** (Use Cases + DI) | ‚ö†Ô∏è OVERKILL | Un conteneur d'injection de d√©pendances et des Use Cases formels pour une CLI de notes ? C'est de l'architecture enterprise plaqu√©e sur un projet simple. Tu vas passer plus de temps sur la plomberie que sur les features. |

**üí° Verdict:** Niveau 1 uniquement. Les niveaux 2-3 sont du cargo cult architecture.

---

#### 9. Duplication de Code et Principe DRY

| Niveau | √âvaluation | Justification |
|--------|------------|---------------|
| **Niveau 1** (Fonction partag√©e basique) | ‚úÖ ESSENTIEL | Extraire `entry_to_dict()` et `dict_to_entry()` prend 30 min et √©limine 40+ lignes dupliqu√©es. ROI imm√©diat. |
| **Niveau 2** (Module serializers d√©di√©) | üëç RECOMMAND√â | Cr√©er `rekall/serializers.py` centralise toute la logique de conversion. Facilite les √©volutions de sch√©ma. |
| **Niveau 3** (Pydantic/dataclass avec serdes) | ‚ö†Ô∏è OVERKILL | Remplacer par des mod√®les Pydantic avec `model_dump()`/`model_validate()` est √©l√©gant mais n√©cessite un refactoring majeur pour peu de gain sur un sch√©ma stable. |

**üí° Verdict:** Niveaux 1-2 recommand√©s. Niveau 3 si refonte majeure pr√©vue.

---

#### 10. CLI Monolithique et Modularisation

| Niveau | √âvaluation | Justification |
|--------|------------|---------------|
| **Niveau 1** (Extraction helpers) | üëç RECOMMAND√â | D√©placer l'init DB/config dans `rekall/config.py` r√©duit le bruit sans restructuration majeure. ~1h de travail. |
| **Niveau 2** (Sous-commandes modulaires) | üü° OPTIONNEL | Cr√©er `commands/export.py`, `commands/integrations.py` am√©liore la navigation mais n√©cessite de toucher tous les imports. Utile si le fichier d√©passe 3000 LOC. |
| **Niveau 3** (Architecture plugins Typer) | ‚ö†Ô∏è OVERKILL | Syst√®me de d√©couverte automatique de commandes avec entry points ? Pour une CLI locale de ~15 commandes, c'est de la sur-architecture. |

**üí° Verdict:** Niveau 1 suffit. Niveau 2 si le fichier continue de grossir.

---

#### 11. Code Mort et Int√©grations Non Raccord√©es

| Niveau | √âvaluation | Justification |
|--------|------------|---------------|
| **Niveau 1** (Vulture basique) | ‚úÖ ESSENTIEL | Ex√©cuter `vulture rekall/` identifie le code mort en 10 secondes. Int√©gration CI triviale. |
| **Niveau 2** (Raccorder ou documenter) | üëç RECOMMAND√â | Les installateurs IDE (Copilot, Windsurf, etc.) sont du code valide mais inaccessible. Soit ajouter des commandes CLI `rekall install-integration`, soit les marquer comme "exp√©rimental". |
| **Niveau 3** (Syst√®me de plugins dynamique) | üü° OPTIONNEL | Utiliser stevedore/pluggy pour charger les int√©grations dynamiquement est √©l√©gant mais complexe. R√©server aux cas o√π tu veux des plugins tiers. |

**üí° Verdict:** Niveaux 1-2 recommand√©s. Niveau 3 si √©cosyst√®me de plugins envisag√©.

---

#### 12. Observabilit√© et Gestion d'Erreurs

| Niveau | √âvaluation | Justification |
|--------|------------|---------------|
| **Niveau 1** (Exceptions cibl√©es + logging) | ‚úÖ ESSENTIEL | Remplacer `except Exception` par des exceptions sp√©cifiques avec `logging.exception()`. Co√ªt minimal, d√©buggabilit√© maximale. |
| **Niveau 2** (Rich/Typer feedback) | üëç RECOMMAND√â | Utiliser `typer.echo()` avec codes couleur Rich pour les erreurs utilisateur. Messages explicites avec suggestions de rem√©diation. |
| **Niveau 3** (Structured logging avec Loguru/structlog) | üü° OPTIONNEL | JSON logs, contexte enrichi, agr√©gation. Utile pour debug complexe mais overkill pour une CLI locale. |

**üí° Verdict:** Niveaux 1-2 obligatoires. Niveau 3 si besoin d'agr√©gation de logs.

---

#### 13. Persistance de Configuration (Int√©grit√©)

| Niveau | √âvaluation | Justification |
|--------|------------|---------------|
| **Niveau 1** (Lib TOML + atomicit√© basique) | ‚úÖ ESSENTIEL | Utiliser `tomli`/`tomli-w` au lieu de manipulation manuelle. √âcriture atomique : `tempfile` + `os.replace()`. |
| **Niveau 2** (fsync + feedback utilisateur) | üëç RECOMMAND√â | Appeler `fsync()` avant rename pour garantir la persistance. Logger/afficher les erreurs d'√©criture. |
| **Niveau 3** (File locking avec fcntl/portalocker) | ‚ö†Ô∏è OVERKILL | Verrous de fichiers pour CLI mono-utilisateur ? Complexit√© inutile. Le pattern atomic write suffit. |

**üí° Verdict:** Niveaux 1-2 couvrent 99% des cas. Niveau 3 seulement si acc√®s concurrents r√©els.

---

#### 14. Durcissement des Archives et Imports

| Niveau | √âvaluation | Justification |
|--------|------------|---------------|
| **Niveau 1** (Limites de taille basiques) | ‚úÖ ESSENTIEL | V√©rifier `file_size` avant extraction. Rejeter archives > N Mo. Co√ªt nul, protection DoS imm√©diate. |
| **Niveau 2** (Validation champs + ratio compression) | üëç RECOMMAND√â | Valider chaque champ JSON (taille contenu, nombre tags). Calculer ratio d√©compression pour d√©tecter zip bombs. |
| **Niveau 3** (Sandbox + quotas ressources) | üü° OPTIONNEL | Limiter m√©moire/CPU du processus d'extraction avec `resource.setrlimit()`. Utile si archives proviennent de sources non fiables. |

**üí° Verdict:** Niveaux 1-2 couvrent les attaques courantes. Niveau 3 pour parano√Øa justifi√©e.

---

#### 15. D√©tection et Correction des Contributions IA

| Niveau | √âvaluation | Justification |
|--------|------------|---------------|
| **Niveau 1** (Ruff √©largi + fix f-strings) | ‚úÖ ESSENTIEL | Activer r√®gles ANN, B, N, PL. Corriger les f-strings manquantes. Co√ªt minimal, d√©tecte 90% des probl√®mes IA. |
| **Niveau 2** (Audit TODO + conventions) | üëç RECOMMAND√â | Scanner les TODO/placeholders, √©tablir guide de style, v√©rifier coh√©rence fonctionnalit√©s/docs. |
| **Niveau 3** (Sloppylint + revue narrative) | üü° OPTIONNEL | Outils sp√©cialis√©s d√©tection IA, revue manuelle des promesses de fonctionnalit√©s. Pour projets collaboratifs. |

**üí° Verdict:** Niveaux 1-2 obligatoires pour tout projet avec contributions IA. Niveau 3 si √©quipe multi-agents.

---

### üèÜ Synth√®se des Recommandations

#### ‚úÖ √Ä impl√©menter absolument (Semaine 1-2)

1. **CI/CD Niveau 1** : pip-audit + Bandit
2. **Permissions SQLite** : chmod 600
3. **uv lock** : Verrouillage des d√©pendances
4. **Ruff basique** : R√®gles E, F, W
5. **Validation Pydantic** : Pour les entr√©es utilisateur
6. **DRY serializers** : Extraire `entry_to_dict()` partag√©e
7. **Vulture** : D√©tection code mort en CI
8. **Exceptions cibl√©es** : Remplacer `except Exception` silencieux
9. **TOML lib** : `tomli-w` au lieu de manipulation manuelle
10. **Limite taille archives** : Rejeter fichiers > N Mo
11. **Ruff √©largi IA** : Activer r√®gles ANN, B, N, PL *(Nouveau)*
12. **Fix f-strings** : Corriger interpolations manquantes (`{var}` ‚Üí f-string) *(Nouveau)*

#### üëç Recommand√© (Semaine 3-4)

1. **CI/CD Niveau 2** : Safety + TruffleHog
2. **Ruff √©tendu** : Ajouter I, B, S, UP
3. **CI avec lockfile** : uv sync --frozen
4. **Documentation RGPD** : Classification des donn√©es
5. **Requ√™tes param√©tr√©es** : Validation FTS
6. **Module serializers** : Cr√©er `rekall/serializers.py`
7. **Raccorder int√©grations** : Commandes CLI pour installateurs IDE
8. **Rich error feedback** : Messages utilisateur avec suggestions
9. **Atomic write + fsync** : √âcriture s√©curis√©e config.toml
10. **Validation ZIP ratio** : D√©tection zip bombs
11. **Audit TODO/placeholders** : Scanner et corriger les TODO non r√©solus *(Nouveau)*
12. **Guide de style** : Documenter conventions PEP 8 + patterns maison *(Nouveau)*

#### üü° Optionnel (selon besoins)

1. **SQLCipher** : Si donn√©es vraiment sensibles
2. **Keyring** : Si SQLCipher activ√©
3. **D√©tection PII regex** : Si exports fr√©quents
4. **Pre-commit hooks** : Si contributeurs externes
5. **CLI modulaire** : Sous-commandes si >3000 LOC
6. **Plugins dynamiques** : Stevedore si √©cosyst√®me tiers
7. **Structured logging** : Loguru/structlog si debug complexe
8. **Sandbox extraction** : `resource.setrlimit()` si sources non fiables
9. **Sloppylint** : D√©tection patterns IA si contributions multi-agents *(Nouveau)*
10. **Revue narrative** : Audit coh√©rence docs/fonctionnalit√©s si √©quipe *(Nouveau)*

#### ‚ö†Ô∏è √Ä √©viter (over-engineering)

1. ~~Semgrep + SARIF~~ ‚Üí Bandit suffit
2. ~~Migration SQLCipher auto~~ ‚Üí Chiffrer d√®s le d√©part
3. ~~Sessions avec timeout~~ ‚Üí Pas de session en CLI
4. ~~Audit logs~~ ‚Üí Pas de valeur pour usage perso
5. ~~Triggers SQL audit~~ ‚Üí Complexit√© inutile
6. ~~Repository Pattern~~ ‚Üí Un seul backend
7. ~~Use Cases + DI~~ ‚Üí <500 LOC, pas besoin
8. ~~Pydantic serdes complet~~ ‚Üí Sch√©ma stable, pas de valeur
9. ~~Architecture plugins Typer~~ ‚Üí ~15 commandes seulement
10. ~~File locking fcntl~~ ‚Üí CLI mono-utilisateur, atomic write suffit
11. ~~AI code detection ML~~ ‚Üí Overkill pour projet personnel *(Nouveau)*

---

## 1. CI/CD et Scans de S√©curit√©

### üî¥ Probl√©matique Identifi√©e

> **[HAUTE] Absence totale de pipeline CI/CD et de scans de vuln√©rabilit√©s**
> - Aucune automatisation pour tests, lint, ou audits (SAST/dep)
> - Risque d'introduire des CVE ou r√©gressions
> - R√©f√©rence: OWASP A03:2025 (Software Supply Chain Failures)

### üìñ Sources Consult√©es

#### ‚úÖ Sources Retenues

| Source | Raison de R√©tention |
|--------|---------------------|
| [pip-audit (GitHub PyPA)](https://github.com/pypa/pip-audit) | **Outil officiel PyPA**, maintenu activement, utilise la base PyPI Advisory Database. Standard de facto pour l'audit des d√©pendances Python. |
| [Safety (GitHub pyupio)](https://github.com/pyupio/safety) | **Alternative mature** avec base de donn√©es propri√©taire plus exhaustive. Offre GitHub Action d√©di√©e. Compl√©mentaire √† pip-audit. |
| [Wiz - CI/CD Security Best Practices](https://www.wiz.io/academy/ci-cd-security-best-practices) | **Guide enterprise-grade** avec m√©triques 2025 (35% des entreprises utilisent des runners mal configur√©s). Approche "shift-left" bien document√©e. |
| [Atmosly - Python CI/CD Pipeline 2025](https://atmosly.com/blog/python-ci-cd-pipeline-mastery-a-complete-guide-for-2025) | **Guide complet 2025** avec exemples GitHub Actions, matrix builds, et bonnes pratiques de s√©curit√© int√©gr√©es. |
| [Bandit (GitHub PyCQA)](https://github.com/PyCQA/bandit) | **SAST officiel Python** par PyCQA. 88% de d√©tection des failles d'injection selon benchmarks OWASP 2024. |

#### ‚ùå Sources Non Retenues

| Source | Raison de Rejet |
|--------|-----------------|
| [Medium - EDTS Automated Security Testing](https://medium.com/edts/automated-security-testing-in-ci-cd-pipelines-using-github-actions-7e974804a92c) | Article g√©n√©raliste sans focus Python, exemples trop simplistes pour une impl√©mentation SOTA. |
| [DevOps Training Institute - 15 GitHub Actions Plugins](https://www.devopstraininginstitute.com/blog/15-most-used-plugins-in-github-actions) | Liste sans profondeur technique, pas de contexte s√©curit√© Python sp√©cifique. |
| [CyberSecurityNews - Building Secure DevOps Pipeline](https://cybersecuritynews.com/ci-cd-security/) | Contenu orient√© marketing, manque d'exemples concrets et de code. |

### üéØ Bonnes Pratiques SOTA 2025

1. **Approche "Shift-Left"** : Int√©grer les tests de s√©curit√© le plus t√¥t possible dans le cycle
2. **Multi-couches de s√©curit√©** :
   - SAST (Static Application Security Testing) : Bandit, Semgrep
   - SCA (Software Composition Analysis) : pip-audit, Safety
   - Secret Scanning : detect-secrets, gitleaks
3. **√âpinglage des Actions** : Utiliser le SHA complet (pas juste `@v4`) pour les actions GitHub
4. **Fail-fast** : Bloquer les merges si vuln√©rabilit√©s critiques d√©tect√©es

### üìà Rem√©diation Graduelle

#### Niveau 1 - Fondations (Semaine 1)
```yaml
# .github/workflows/security.yml
name: Security Checks
on: [push, pull_request]

jobs:
  security:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install pip-audit bandit[toml]

      - name: Run pip-audit
        run: pip-audit --require-hashes --strict

      - name: Run Bandit
        run: bandit -r rekall/ -c pyproject.toml
```

#### Niveau 2 - Interm√©diaire (Semaine 2-3)
```yaml
# Ajouter Safety pour couverture compl√©mentaire
- name: Run Safety
  run: |
    pip install safety
    safety check --full-report

# Ajouter secret scanning
- name: Detect Secrets
  uses: trufflesecurity/trufflehog@main
  with:
    path: ./
    base: ${{ github.event.repository.default_branch }}
```

#### Niveau 3 - Avanc√© (Mois 1)
```yaml
# Configuration compl√®te avec Semgrep
- name: Semgrep SAST
  uses: returntocorp/semgrep-action@v1
  with:
    config: >-
      p/python
      p/security-audit
      p/owasp-top-ten

# Rapport SARIF pour GitHub Security tab
- name: Upload SARIF
  uses: github/codeql-action/upload-sarif@v2
  with:
    sarif_file: results.sarif
```

#### Configuration pyproject.toml
```toml
[tool.bandit]
exclude_dirs = ["tests", ".venv", "__pycache__"]
skips = ["B101"]  # skip assert warnings in tests
targets = ["rekall"]

[tool.bandit.assert_used]
skips = ["*_test.py", "*test_*.py"]
```

---

## 2. Chiffrement des Donn√©es SQLite

### üî¥ Probl√©matique Identifi√©e

> **[HAUTE] Donn√©es stock√©es en clair dans SQLite sans protection**
> - La base locale n'emploie ni chiffrement au repos ni contr√¥le d'acc√®s
> - Compromission machine ‚áí fuite de notes potentiellement sensibles
> - R√©f√©rences: OWASP A04:2025 (Cryptographic Failures), CWE-311

### üìñ Sources Consult√©es

#### ‚úÖ Sources Retenues

| Source | Raison de R√©tention |
|--------|---------------------|
| [Charles Leifer - Encrypted SQLite with SQLCipher](https://charlesleifer.com/blog/encrypted-sqlite-databases-with-python-and-sqlcipher/) | **Auteur de Peewee ORM**, expert reconnu. Guide pratique avec exemples Python fonctionnels. Recommande sqlcipher3-binary. |
| [sqlcipher3 (GitHub coleifer)](https://github.com/coleifer/sqlcipher3) | **Bindings Python maintenus** (contrairement √† pysqlcipher3). Package wheel autonome disponible (sqlcipher3-binary). |
| [Blackhawk - Best Practices for Securing SQLite](https://blackhawk.sh/en/blog/best-practices-for-securing-sqlite/) | **Guide complet** couvrant permissions fichiers, WAL, et chiffrement. Approche d√©fense en profondeur. |
| [Tencent Cloud - SQLite Encryption](https://www.tencentcloud.com/techpedia/102689) | **Perspective enterprise** avec comparaison des options (SQLCipher, SEE, wxSQLite3). M√©triques de performance incluses. |

#### ‚ùå Sources Non Retenues

| Source | Raison de Rejet |
|--------|-----------------|
| [pysqlcipher3 (rigglemania)](https://github.com/rigglemania/pysqlcipher3) | **Projet abandonn√©** - dernier commit 2019. Documentation SQLAlchemy confirme qu'il n'est plus maintenu. |
| [pysqlcipher (PyPI)](https://pypi.org/project/pysqlcipher/) | **Obsol√®te** - Python 2 uniquement, incompatible Python 3.9+. |
| [privacee/pysqlcipher3](https://github.com/privacee/pysqlcipher3) | **Fork non officiel** sans activit√© significative. Risque de s√©curit√© √† utiliser un fork non audit√©. |
| [Devart Python Connector](https://docs.devart.com/python/sqlite/database-encryption.htm) | **Solution propri√©taire payante**, non adapt√© √† un projet open-source. |

### üéØ Bonnes Pratiques SOTA 2025

1. **SQLCipher** : Standard de facto pour le chiffrement SQLite (AES-256-CBC)
2. **Gestion des cl√©s** : Utiliser le keyring syst√®me (voir section 3)
3. **Protection des fichiers** :
   - Permissions `chmod 600` sur le fichier .db
   - Prot√©ger aussi les fichiers `-wal` et `-shm`
4. **Migration transparente** : Supporter les bases existantes non chiffr√©es

### üìà Rem√©diation Graduelle

#### Niveau 1 - Permissions Fichiers (Imm√©diat)
```python
# rekall/db.py - Ajout apr√®s cr√©ation de la base
import os
import stat

def secure_db_permissions(db_path: Path) -> None:
    """Restreint les permissions du fichier DB √† l'utilisateur seul."""
    os.chmod(db_path, stat.S_IRUSR | stat.S_IWUSR)  # 600

    # Prot√©ger aussi les fichiers WAL si pr√©sents
    for suffix in ['-wal', '-shm']:
        wal_path = db_path.parent / f"{db_path.name}{suffix}"
        if wal_path.exists():
            os.chmod(wal_path, stat.S_IRUSR | stat.S_IWUSR)
```

#### Niveau 2 - Chiffrement Optionnel (Semaine 2-4)
```python
# rekall/crypto.py
from typing import Optional
import sqlcipher3

def get_encrypted_connection(
    db_path: str,
    passphrase: Optional[str] = None
) -> sqlcipher3.Connection:
    """
    Ouvre une connexion SQLite chiffr√©e avec SQLCipher.

    Args:
        db_path: Chemin vers la base de donn√©es
        passphrase: Phrase de passe pour le chiffrement
    """
    conn = sqlcipher3.connect(db_path)

    if passphrase:
        # Configuration SQLCipher optimale
        conn.execute(f"PRAGMA key = '{passphrase}'")
        conn.execute("PRAGMA cipher_page_size = 4096")
        conn.execute("PRAGMA kdf_iter = 256000")  # PBKDF2 iterations
        conn.execute("PRAGMA cipher_hmac_algorithm = HMAC_SHA512")
        conn.execute("PRAGMA cipher_kdf_algorithm = PBKDF2_HMAC_SHA512")

    return conn
```

#### Niveau 3 - Migration Automatique (Mois 1-2)
```python
# rekall/migration.py
def migrate_to_encrypted(
    plain_db: Path,
    encrypted_db: Path,
    passphrase: str
) -> None:
    """
    Migre une base non chiffr√©e vers une base chiffr√©e.

    Utilise sqlcipher_export pour une migration atomique.
    """
    import sqlite3
    import sqlcipher3

    # Ouvrir la base source en lecture seule
    src = sqlite3.connect(f"file:{plain_db}?mode=ro", uri=True)

    # Cr√©er la base chiffr√©e
    dst = sqlcipher3.connect(str(encrypted_db))
    dst.execute(f"PRAGMA key = '{passphrase}'")

    # Export atomique
    src.backup(dst)

    src.close()
    dst.close()

    # Supprimer l'ancienne base de fa√ßon s√©curis√©e
    secure_delete(plain_db)
```

#### D√©pendances √† ajouter
```toml
# pyproject.toml
[project.optional-dependencies]
encryption = [
    "sqlcipher3-binary>=0.5.0",
]
```

---

## 3. Authentification et Autorisation

### üî¥ Probl√©matique Identifi√©e

> **[MOYENNE] Absence d'authentification/autorisation**
> - Toute personne ayant acc√®s au shell peut lire/√©crire la base
> - Fuite ou corruption si poste partag√©/compromis
> - R√©f√©rence: OWASP A01:2025 (Broken Access Control)

### üìñ Sources Consult√©es

#### ‚úÖ Sources Retenues

| Source | Raison de R√©tention |
|--------|---------------------|
| [keyring (PyPI)](https://pypi.org/project/keyring/) | **Biblioth√®que standard de facto** pour le stockage s√©curis√© de credentials. Cross-platform (macOS Keychain, Windows Credential Locker, Linux Secret Service). |
| [keyring Documentation](https://keyring.readthedocs.io/) | **Documentation officielle** avec exemples d'utilisation, backends support√©s, et configuration avanc√©e. |
| [Martin Heinz - Secure Password Handling](https://martinheinz.dev/blog/59) | **Article technique approfondi** comparant les approches (keyring, getpass, environment). Recommandations claires avec justifications. |
| [CLIMB - 10 Python Keyring Best Practices](https://climbtheladder.com/10-python-keyring-best-practices/) | **Checklist pratique** : least privilege, rotation, backup s√©curis√©. Orient√© production. |

#### ‚ùå Sources Non Retenues

| Source | Raison de Rejet |
|--------|-----------------|
| [GeeksforGeeks - Storing passwords with keyring](https://www.geeksforgeeks.org/python/storing-passwords-with-python-keyring/) | **Contenu trop basique**, exemples sans consid√©rations de s√©curit√© avanc√©es. Pas de gestion d'erreurs. |
| [alexwlchan - Use keyring](https://alexwlchan.net/2016/you-should-use-keyring/) | **Article de 2016**, informations potentiellement obsol√®tes concernant les backends Linux modernes. |
| [pythonmana - Secure password processing](https://pythonmana.com/2022/01/202201050416151089.html) | **Qualit√© douteuse**, traduction automatique visible, code non test√©. |

### üéØ Bonnes Pratiques SOTA 2025

1. **Keyring syst√®me** : D√©l√©guer le stockage des secrets au syst√®me d'exploitation
2. **Principe du moindre privil√®ge** : Ne stocker que les secrets strictement n√©cessaires
3. **Verrouillage automatique** : Timeout d'inactivit√© configurable
4. **Journalisation d'acc√®s** : Logger les acc√®s pour audit (sans logger les secrets !)
5. **Fallback s√©curis√©** : Demander le mot de passe si keyring indisponible

### üìà Rem√©diation Graduelle

#### Niveau 1 - Protection par Passphrase (Semaine 1-2)
```python
# rekall/auth.py
import getpass
import keyring
from typing import Optional

SERVICE_NAME = "rekall"
USERNAME = "db_passphrase"

def get_passphrase(prompt: bool = True) -> Optional[str]:
    """
    R√©cup√®re la passphrase depuis le keyring syst√®me.

    Args:
        prompt: Si True, demande √† l'utilisateur si non trouv√©e

    Returns:
        La passphrase ou None si non disponible
    """
    # Essayer le keyring syst√®me
    passphrase = keyring.get_password(SERVICE_NAME, USERNAME)

    if passphrase is None and prompt:
        passphrase = getpass.getpass("Passphrase Rekall: ")

        # Proposer de sauvegarder
        if input("Sauvegarder dans le keyring? [o/N] ").lower() == 'o':
            set_passphrase(passphrase)

    return passphrase


def set_passphrase(passphrase: str) -> None:
    """Stocke la passphrase dans le keyring syst√®me."""
    keyring.set_password(SERVICE_NAME, USERNAME, passphrase)


def delete_passphrase() -> None:
    """Supprime la passphrase du keyring."""
    try:
        keyring.delete_password(SERVICE_NAME, USERNAME)
    except keyring.errors.PasswordDeleteError:
        pass  # D√©j√† supprim√©e
```

#### Niveau 2 - Mode Prot√©g√© avec Verrouillage (Semaine 3-4)
```python
# rekall/session.py
import time
from dataclasses import dataclass
from typing import Optional

@dataclass
class Session:
    """Session authentifi√©e avec timeout."""

    passphrase: str
    created_at: float
    last_activity: float
    timeout_seconds: int = 300  # 5 minutes par d√©faut

    def is_valid(self) -> bool:
        """V√©rifie si la session est encore valide."""
        return (time.time() - self.last_activity) < self.timeout_seconds

    def touch(self) -> None:
        """Met √† jour le timestamp d'activit√©."""
        self.last_activity = time.time()

    def lock(self) -> None:
        """Verrouille la session (efface la passphrase de la m√©moire)."""
        # √âcraser la passphrase en m√©moire
        self.passphrase = "x" * len(self.passphrase)
        self.passphrase = None


_current_session: Optional[Session] = None

def require_auth(func):
    """D√©corateur exigeant une session authentifi√©e."""
    def wrapper(*args, **kwargs):
        global _current_session

        if _current_session is None or not _current_session.is_valid():
            passphrase = get_passphrase(prompt=True)
            if not passphrase:
                raise AuthenticationError("Authentification requise")
            _current_session = Session(
                passphrase=passphrase,
                created_at=time.time(),
                last_activity=time.time()
            )

        _current_session.touch()
        return func(*args, **kwargs)

    return wrapper
```

#### Niveau 3 - Journalisation d'Acc√®s (Mois 1)
```python
# rekall/audit.py
import logging
from datetime import datetime
from pathlib import Path

def setup_audit_log(log_path: Path) -> logging.Logger:
    """Configure un logger d'audit s√©curis√©."""

    logger = logging.getLogger("rekall.audit")
    logger.setLevel(logging.INFO)

    # Handler fichier avec rotation
    handler = logging.handlers.RotatingFileHandler(
        log_path,
        maxBytes=1_000_000,  # 1 MB
        backupCount=5
    )

    # Format d'audit
    formatter = logging.Formatter(
        '%(asctime)s | %(levelname)s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)

    return logger


def log_access(action: str, resource: str, success: bool) -> None:
    """
    Journalise un acc√®s.

    IMPORTANT: Ne JAMAIS logger de secrets ou donn√©es sensibles !
    """
    logger = logging.getLogger("rekall.audit")
    status = "SUCCESS" if success else "FAILURE"
    logger.info(f"{status} | {action} | {resource}")
```

---

## 4. Gestion des PII et Conformit√© RGPD

### üî¥ Probl√©matique Identifi√©e

> **[MOYENNE] Politique de r√©tention et masquage non d√©finie**
> - Les captures peuvent inclure PII/secrets
> - Pas de m√©canisme de purge/masquage
> - Non-conformit√© RGPD potentielle

### üìñ Sources Consult√©es

#### ‚úÖ Sources Retenues

| Source | Raison de R√©tention |
|--------|---------------------|
| [Alation - GDPR Data Compliance 2025](https://www.alation.com/blog/gdpr-data-compliance-best-practices-2025/) | **Guide enterprise 2025** avec focus sur les amendes r√©centes (8-22M‚Ç¨) et les articles RGPD concern√©s. Approche lifecycle management. |
| [Accutive Security - GDPR Data Masking Guide 2025](https://accutivesecurity.com/how-to-implement-gdpr-data-masking-without-sacrificing-usability/) | **Guide technique** comparant anonymisation vs pseudonymisation. Exemples de techniques de masquage pr√©servant l'utilit√©. |
| [Sentra - PII Compliance Checklist 2025](https://www.sentra.io/learn/pii-compliance-checklist) | **Checklist actionnable** avec 17 types de PII √† consid√©rer. Framework de classification des donn√©es. |
| [HydroXai - pii-masker (GitHub)](https://github.com/HydroXai/pii-masker) | **Outil open-source** bas√© sur DeBERTa-v3 pour d√©tection/masquage automatique de PII. API Python simple. |
| [MSTICPy - Data Masking](https://msticpy.readthedocs.io/en/latest/data_acquisition/DataMasking.html) | **Biblioth√®que Microsoft** pour l'obfuscation de donn√©es. Fonctions de hachage et mapping al√©atoire. |

#### ‚ùå Sources Non Retenues

| Source | Raison de Rejet |
|--------|-----------------|
| [Ground Labs - PII and Data Retention](https://www.groundlabs.com/blog/what-is-pii-for-gdpr) | **Contenu orient√© produit** (promotion de leur solution), peu de valeur technique pour l'impl√©mentation. |
| [pii.ai - GDPR Compliant Guide](https://www.pii.ai/blog/gdpr-compliant-the-complete-2025-guide) | **Site commercial** avec contenu g√©n√©rique, pas d'exemples de code ou d'architecture. |
| [ByteTools - AI Privacy Guide](https://bytetools.io/guides/ai-privacy-best-practices) | **Hors scope** - focalis√© sur l'IA/LLM, pas sur les applications de gestion de donn√©es locales. |
| [Nightfall AI - PII Management](https://www.nightfall.ai/blog/storing-pii-in-the-cloud-best-practices-and-regulatory-considerations) | **Orient√© cloud/SaaS**, recommandations non applicables √† une CLI locale. |

### üéØ Bonnes Pratiques SOTA 2025

1. **Classification des donn√©es** : Identifier et taguer les champs contenant potentiellement des PII
2. **Minimisation** : Ne collecter que les donn√©es strictement n√©cessaires
3. **R√©tention d√©finie** : Politique de dur√©e de conservation document√©e
4. **Droit √† l'effacement** : Commande de purge s√©curis√©e (Article 17 RGPD)
5. **Masquage √† l'export** : Options d'anonymisation pour les exports

### üìà Rem√©diation Graduelle

#### Niveau 1 - Classification et Documentation (Semaine 1)
```python
# rekall/models.py
from enum import Enum
from dataclasses import dataclass, field
from datetime import datetime
from typing import Optional

class DataClassification(Enum):
    """Classification RGPD des donn√©es."""
    PUBLIC = "public"           # Donn√©es non sensibles
    INTERNAL = "internal"       # Donn√©es internes
    CONFIDENTIAL = "confidential"  # Donn√©es personnelles
    RESTRICTED = "restricted"   # Donn√©es sensibles (sant√©, opinions, etc.)


@dataclass
class Note:
    """Mod√®le de note avec m√©tadonn√©es de classification."""

    id: int
    content: str
    created_at: datetime
    updated_at: datetime

    # M√©tadonn√©es RGPD
    classification: DataClassification = DataClassification.INTERNAL
    contains_pii: bool = False
    retention_days: Optional[int] = None  # None = r√©tention ind√©finie

    def is_expired(self) -> bool:
        """V√©rifie si la note a d√©pass√© sa p√©riode de r√©tention."""
        if self.retention_days is None:
            return False
        age = (datetime.now() - self.created_at).days
        return age > self.retention_days
```

#### Niveau 2 - D√©tection Automatique de PII (Semaine 2-4)
```python
# rekall/pii.py
import re
from typing import List, Tuple

# Patterns de d√©tection de PII (regex simples pour v1)
PII_PATTERNS = {
    "email": r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
    "phone_fr": r'\b(?:(?:\+|00)33|0)\s*[1-9](?:[\s.-]*\d{2}){4}\b',
    "iban": r'\b[A-Z]{2}\d{2}[A-Z0-9]{4}\d{7}([A-Z0-9]?){0,16}\b',
    "credit_card": r'\b(?:\d{4}[-\s]?){3}\d{4}\b',
    "ssn_fr": r'\b[12]\s?\d{2}\s?\d{2}\s?\d{2}\s?\d{3}\s?\d{3}\s?\d{2}\b',
}


def detect_pii(text: str) -> List[Tuple[str, str, int, int]]:
    """
    D√©tecte les PII dans un texte.

    Returns:
        Liste de tuples (type, valeur, d√©but, fin)
    """
    findings = []

    for pii_type, pattern in PII_PATTERNS.items():
        for match in re.finditer(pattern, text, re.IGNORECASE):
            findings.append((
                pii_type,
                match.group(),
                match.start(),
                match.end()
            ))

    return findings


def mask_pii(text: str, mask_char: str = "*") -> str:
    """
    Masque les PII d√©tect√©s dans un texte.

    Pr√©serve les premiers et derniers caract√®res pour l'identification.
    """
    result = text

    for pii_type, value, start, end in sorted(
        detect_pii(text),
        key=lambda x: x[2],
        reverse=True  # Traiter de la fin au d√©but
    ):
        if len(value) > 4:
            masked = value[0] + mask_char * (len(value) - 2) + value[-1]
        else:
            masked = mask_char * len(value)

        result = result[:start] + masked + result[end:]

    return result
```

#### Niveau 3 - Commandes de Purge et R√©tention (Mois 1-2)
```python
# rekall/retention.py
from datetime import datetime, timedelta
from typing import Optional
import logging

logger = logging.getLogger(__name__)


def purge_expired_notes(db, dry_run: bool = True) -> int:
    """
    Purge les notes ayant d√©pass√© leur p√©riode de r√©tention.

    Args:
        db: Connexion √† la base de donn√©es
        dry_run: Si True, simule sans supprimer

    Returns:
        Nombre de notes purg√©es (ou √† purger si dry_run)
    """
    cursor = db.execute("""
        SELECT id, created_at, retention_days
        FROM notes
        WHERE retention_days IS NOT NULL
    """)

    expired_ids = []
    now = datetime.now()

    for row in cursor:
        note_id, created_at, retention_days = row
        expiry = created_at + timedelta(days=retention_days)
        if now > expiry:
            expired_ids.append(note_id)

    if not dry_run and expired_ids:
        placeholders = ','.join('?' * len(expired_ids))
        db.execute(
            f"DELETE FROM notes WHERE id IN ({placeholders})",
            expired_ids
        )
        db.commit()
        logger.info(f"Purg√© {len(expired_ids)} notes expir√©es")

    return len(expired_ids)


def secure_delete_note(db, note_id: int) -> None:
    """
    Suppression s√©curis√©e d'une note (droit √† l'oubli RGPD).

    √âcrase le contenu avant suppression pour √©viter la r√©cup√©ration.
    """
    # √âcraser le contenu
    db.execute(
        "UPDATE notes SET content = ?, updated_at = ? WHERE id = ?",
        ("[DELETED]", datetime.now(), note_id)
    )

    # Puis supprimer
    db.execute("DELETE FROM notes WHERE id = ?", (note_id,))
    db.commit()

    # VACUUM pour lib√©rer l'espace et √©viter r√©cup√©ration
    db.execute("VACUUM")
```

#### Documentation √† ajouter au README
```markdown
## Politique de Confidentialit√© et R√©tention

### Classification des Donn√©es
- **PUBLIC**: Informations non sensibles
- **INTERNAL**: Notes personnelles standard
- **CONFIDENTIAL**: Contient des donn√©es personnelles (PII)
- **RESTRICTED**: Donn√©es sensibles (sant√©, finances)

### R√©tention
Par d√©faut, les notes sont conserv√©es ind√©finiment. Vous pouvez d√©finir
une p√©riode de r√©tention par note avec `--retention-days`.

### Droit √† l'Effacement
Utilisez `rekall delete --secure <id>` pour une suppression conforme RGPD.
```

---

## 5. Validation des Entr√©es Utilisateur

### üî¥ Probl√©matique Identifi√©e

> **[MOYENNE] V√©rification limit√©e des entr√©es utilisateur**
> - Peu de validation/sanitation des contenus stock√©s
> - Risque d'injection FTS ou de corruption logique
> - R√©f√©rences: OWASP A05:2025 (Injection)

### üìñ Sources Consult√©es

#### ‚úÖ Sources Retenues

| Source | Raison de R√©tention |
|--------|---------------------|
| [OWASP Input Validation Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Input_Validation_Cheat_Sheet.html) | **Source autoritaire** OWASP. Principes fondamentaux : whitelist > blacklist, validation + encodage contextuels. |
| [Pydantic Documentation](https://docs.pydantic.dev/latest/) | **Standard Python** pour la validation de donn√©es. Type hints natifs, validation automatique, excellent √©cosyst√®me. |
| [Real Python - Prevent SQL Injection](https://realpython.com/prevent-python-sql-injection/) | **Tutoriel pratique** avec exemples sqlite3, parameterized queries, et pi√®ges courants. Qualit√© √©ditoriale Real Python. |
| [johal.in - Pydantic Validation Layers 2025](https://johal.in/pydantic-validation-layers-secure-python-ml-input-sanitization-2025/) | **Article r√©cent** sur les couches de validation, applicable au-del√† du ML. Patterns d√©fensifs modernes. |
| [SQLite FTS3/FTS4 Documentation](https://www.sqlite.org/fts3.html) | **Documentation officielle** SQLite. Essentiel pour comprendre le MATCH operator et ses particularit√©s. |

#### ‚ùå Sources Non Retenues

| Source | Raison de Rejet |
|--------|-----------------|
| [freedium.cfd - Input Validation Best Practices](https://freedium.cfd/a2c255b858e0) | **Mirror non officiel** de Medium, potentiellement modifi√©. Pr√©f√©rer la source originale. |
| [spsanderson.com - Python Input Validation Beginner's Guide](https://www.spsanderson.com/steveondata/posts/2025-07-16/) | **Niveau trop basique**, destin√© aux d√©butants absolus. Pas de consid√©rations s√©curit√© avanc√©es. |
| [toxigon.com - FastAPI Security](https://toxigon.com/python-fastapi-security-best-practices-2025) | **Hors scope** - sp√©cifique FastAPI/web, non applicable √† une CLI. |
| [moldstud.com - Backend Validation Tips](https://moldstud.com/articles/p-essential-data-validation-sanitization-practices-for-backend-developers-best-backend-development-tips-2025) | **Contenu g√©n√©rique** sans focus Python, exemples dans d'autres langages. |

### üéØ Bonnes Pratiques SOTA 2025

1. **Validation en couches** : Valider √† l'entr√©e ET avant le stockage
2. **Whitelist > Blacklist** : 30% plus efficace selon OWASP
3. **Requ√™tes param√©tr√©es** : TOUJOURS utiliser les placeholders `?`
4. **Limites explicites** : Longueurs max, formats attendus
5. **Encodage contextuel** : √âchapper selon le contexte de sortie

### üìà Rem√©diation Graduelle

#### Niveau 1 - Validation Pydantic (Semaine 1)
```python
# rekall/validators.py
from pydantic import BaseModel, Field, field_validator
from typing import Optional
from datetime import datetime
import re

class NoteInput(BaseModel):
    """Validation des entr√©es pour la cr√©ation de notes."""

    content: str = Field(
        min_length=1,
        max_length=100_000,  # 100 KB max
        description="Contenu de la note"
    )

    tags: Optional[list[str]] = Field(
        default=None,
        max_length=20,  # Max 20 tags
        description="Tags associ√©s"
    )

    classification: str = Field(
        default="internal",
        pattern=r"^(public|internal|confidential|restricted)$"
    )

    @field_validator('content')
    @classmethod
    def sanitize_content(cls, v: str) -> str:
        """Nettoie le contenu tout en pr√©servant le formatage."""
        # Supprimer les caract√®res de contr√¥le (sauf newline, tab)
        v = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f]', '', v)

        # Normaliser les fins de ligne
        v = v.replace('\r\n', '\n').replace('\r', '\n')

        return v.strip()

    @field_validator('tags')
    @classmethod
    def validate_tags(cls, v: Optional[list[str]]) -> Optional[list[str]]:
        """Valide et nettoie les tags."""
        if v is None:
            return None

        cleaned = []
        for tag in v:
            # Tags alphanum√©riques + tirets uniquement
            tag = re.sub(r'[^a-zA-Z0-9\-_]', '', tag.strip().lower())
            if tag and len(tag) <= 50:
                cleaned.append(tag)

        return cleaned[:20] if cleaned else None


class SearchQuery(BaseModel):
    """Validation des requ√™tes de recherche."""

    query: str = Field(
        min_length=1,
        max_length=500,
        description="Requ√™te de recherche"
    )

    limit: int = Field(
        default=50,
        ge=1,
        le=1000,
        description="Nombre max de r√©sultats"
    )

    @field_validator('query')
    @classmethod
    def sanitize_fts_query(cls, v: str) -> str:
        """
        Nettoie la requ√™te pour SQLite FTS.

        √âchappe les caract√®res sp√©ciaux FTS pour √©viter les injections.
        """
        # Caract√®res sp√©ciaux FTS √† √©chapper
        fts_special = ['*', '"', '(', ')', 'OR', 'AND', 'NOT', 'NEAR']

        result = v
        for char in ['"', '*', '(', ')']:
            result = result.replace(char, f'"{char}"')

        # Limiter la longueur des termes individuels
        terms = result.split()
        terms = [t[:100] for t in terms]  # Max 100 chars par terme

        return ' '.join(terms)
```

#### Niveau 2 - Requ√™tes Param√©tr√©es Strictes (Semaine 2)
```python
# rekall/db.py - Am√©lioration des requ√™tes existantes

def search_notes(db, query: str, limit: int = 50) -> list:
    """
    Recherche full-text avec requ√™tes param√©tr√©es.

    IMPORTANT: Toujours utiliser des param√®tres, jamais de f-strings !
    """
    # Valider l'entr√©e
    validated = SearchQuery(query=query, limit=limit)

    # Requ√™te param√©tr√©e - le ? est OBLIGATOIRE
    cursor = db.execute(
        """
        SELECT id, content, snippet(notes_fts, 1, '<mark>', '</mark>', '...', 32)
        FROM notes_fts
        WHERE notes_fts MATCH ?
        ORDER BY rank
        LIMIT ?
        """,
        (validated.query, validated.limit)
    )

    return cursor.fetchall()


def insert_note(db, content: str, **kwargs) -> int:
    """
    Ins√®re une note avec validation stricte.
    """
    # Validation via Pydantic
    validated = NoteInput(content=content, **kwargs)

    cursor = db.execute(
        """
        INSERT INTO notes (content, classification, created_at, updated_at)
        VALUES (?, ?, ?, ?)
        """,
        (
            validated.content,
            validated.classification,
            datetime.now(),
            datetime.now()
        )
    )

    db.commit()
    return cursor.lastrowid
```

#### Niveau 3 - Contraintes Base de Donn√©es (Mois 1)
```python
# rekall/migrations/003_add_constraints.py
"""
Migration: Ajouter des contraintes CHECK √† la base de donn√©es.

Ces contraintes servent de derni√®re ligne de d√©fense.
"""

MIGRATION_SQL = """
-- Contraintes sur la table notes
ALTER TABLE notes ADD CONSTRAINT chk_content_length
    CHECK (length(content) <= 100000);

ALTER TABLE notes ADD CONSTRAINT chk_classification
    CHECK (classification IN ('public', 'internal', 'confidential', 'restricted'));

-- Index pour am√©liorer les performances de validation
CREATE INDEX IF NOT EXISTS idx_notes_classification
    ON notes(classification);

-- Table d'audit des modifications
CREATE TABLE IF NOT EXISTS notes_audit (
    id INTEGER PRIMARY KEY,
    note_id INTEGER NOT NULL,
    action TEXT NOT NULL CHECK (action IN ('INSERT', 'UPDATE', 'DELETE')),
    old_content TEXT,
    new_content TEXT,
    changed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    changed_by TEXT
);

-- Trigger d'audit
CREATE TRIGGER IF NOT EXISTS audit_notes_update
AFTER UPDATE ON notes
BEGIN
    INSERT INTO notes_audit (note_id, action, old_content, new_content)
    VALUES (OLD.id, 'UPDATE', OLD.content, NEW.content);
END;
"""
```

---

## 6. Verrouillage des D√©pendances

### üî¥ Probl√©matique Identifi√©e

> **[BASSE] Absence de verrouillage des versions**
> - Contraintes larges `>=` exposent aux changements non ma√Ætris√©s
> - Builds non reproductibles
> - R√©f√©rence: OWASP A03:2025 (Software Supply Chain Failures)

### üìñ Sources Consult√©es

#### ‚úÖ Sources Retenues

| Source | Raison de R√©tention |
|--------|---------------------|
| [uv Documentation - Locking](https://docs.astral.sh/uv/pip/compile/) | **Documentation officielle** du gestionnaire moderne d'Astral. Lockfiles universels cross-platform, int√©gration native pyproject.toml. |
| [PEP 751](https://peps.python.org/pep-0751/) | **Standard en cours** pour le format de lockfile Python. Contexte important pour comprendre l'√©volution de l'√©cosyst√®me. |
| [Lincoln Loop - pip-tools](https://lincolnloop.com/blog/python-dependency-locking-pip-tools/) | **Guide pratique pip-tools** par une agence Django reconnue. Workflow requirements.in ‚Üí requirements.txt bien expliqu√©. |
| [Syntal - Poetry/uv Lockfile Strategies](https://medium.com/@sparknp1/8-poetry-uv-lockfile-strategies-that-tame-dependency-hell-4bbf63fee566) | **Article 2025** comparant 8 strat√©gies de lockfiles. Cas d'usage enterprise avec multi-environnements. |
| [Loopwerk - Poetry vs uv](https://www.loopwerk.io/articles/2024/python-poetry-vs-uv/) | **Comparaison objective** avec benchmarks. Aide au choix d'outil selon le contexte projet. |

#### ‚ùå Sources Non Retenues

| Source | Raison de Rejet |
|--------|-----------------|
| [Envelope - Poetry vs Uv vs Pip](https://envelope.dev/blog/poetry-vs-uv-vs-pip-choosing-the-right-package-installer) | **Contenu superficiel**, pas de recommandations concr√®tes pour la s√©curit√© supply chain. |
| [dimasyotama - Python Packaging Landscape](https://dimasyotama.medium.com/navigating-the-python-packaging-landscape-pip-vs-poetry-vs-uv-a-developers-guide-49a9c93caf9c) | **Article g√©n√©raliste** sans focus sur le verrouillage et la reproductibilit√©. |
| [pydevtools handbook](https://pydevtools.com/handbook/how-to-use-a-uv-lockfile-for-reproducible-python-environments/) | **Site peu connu**, contenu non v√©rifi√©, risque de recommandations obsol√®tes. |

### üéØ Bonnes Pratiques SOTA 2025

1. **Outil moderne** : Pr√©f√©rer `uv` (2025) ou Poetry pour le verrouillage automatique
2. **Lockfile universel** : uv.lock capture toutes les plateformes dans un seul fichier
3. **Hash-pinning** : V√©rifier l'int√©grit√© des packages avec les hashes
4. **CI reproductible** : Utiliser `--frozen` ou `sync` au lieu de `install`
5. **S√©paration dev/prod** : Groupes de d√©pendances distincts

### üìà Rem√©diation Graduelle

#### Niveau 1 - Migration vers uv (Semaine 1)
```bash
# Installation de uv (recommand√© 2025)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Initialiser le lockfile depuis pyproject.toml existant
cd rekall
uv lock

# Le fichier uv.lock est cr√©√© automatiquement
```

```toml
# pyproject.toml - Mise √† jour
[project]
name = "rekall"
version = "0.1.0"
requires-python = ">=3.9"

dependencies = [
    "typer>=0.9.0",
    "rich>=13.0.0",
    "sqlite-utils>=3.35",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "ruff>=0.1.0",
    "bandit[toml]>=1.7.0",
]

encryption = [
    "sqlcipher3-binary>=0.5.0",
]

[tool.uv]
# Exiger un lockfile √† jour
locked = true
```

#### Niveau 2 - CI avec Lockfile (Semaine 2)
```yaml
# .github/workflows/ci.yml
name: CI

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11', '3.12']

    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: "latest"

      - name: Set up Python ${{ matrix.python-version }}
        run: uv python install ${{ matrix.python-version }}

      - name: Install dependencies (locked)
        run: uv sync --frozen  # √âchoue si lockfile d√©synchronis√©

      - name: Run tests
        run: uv run pytest tests/ -v --cov=rekall

      - name: Verify lockfile is up to date
        run: |
          uv lock --check
          if [ $? -ne 0 ]; then
            echo "::error::Lockfile out of sync. Run 'uv lock' locally."
            exit 1
          fi
```

#### Niveau 3 - Audit et Hash Verification (Mois 1)
```yaml
# .github/workflows/security.yml (extension)
jobs:
  dependency-audit:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v4

      - name: Export requirements with hashes
        run: uv export --format requirements-txt --hashes > requirements.txt

      - name: Audit dependencies
        run: |
          uv pip install pip-audit
          pip-audit -r requirements.txt --require-hashes --strict

      - name: Check for yanked packages
        run: uv pip check
```

```toml
# pyproject.toml - Configuration uv avanc√©e
[tool.uv]
locked = true

[tool.uv.sources]
# Forcer les sources officielles uniquement
rekall = { index = "pypi" }

[tool.uv.pip]
# Options de s√©curit√©
require-hashes = true
no-binary = ["pyyaml"]  # Compiler depuis les sources pour audit
```

---

## 7. Qualit√© de Code et Linting

### üî¥ Probl√©matique Identifi√©e

> **[BASSE] Style lint partiel**
> - Ruff configur√© uniquement sur r√®gles basiques
> - Pas d'ex√©cution CI

### üìñ Sources Consult√©es

#### ‚úÖ Sources Retenues

| Source | Raison de R√©tention |
|--------|---------------------|
| [Ruff Documentation](https://docs.astral.sh/ruff/) | **Source officielle** Astral. Configuration exhaustive, 800+ r√®gles document√©es, exemples pyproject.toml. |
| [Ruff Configuration Guide](https://docs.astral.sh/ruff/configuration/) | **Guide officiel** pour la configuration. Explique preview mode, version pinning, et int√©gration CI. |
| [Real Python - Ruff Python Linter](https://realpython.com/ruff-python/) | **Tutoriel approfondi** par Real Python. Progression p√©dagogique, exemples concrets, bonnes pratiques d'adoption. |
| [Better Stack - Linting with Ruff](https://betterstack.com/community/guides/scaling-python/ruff-explained/) | **Guide pratique** avec comparaisons de performance (10-100x plus rapide). Workflow pre-commit inclus. |
| [GPXZ - How to configure ruff](https://www.gpxz.io/blog/ruff) | **Article technique** avec configuration progressive. Strat√©gie d'adoption graduelle bien expliqu√©e. |

#### ‚ùå Sources Non Retenues

| Source | Raison de Rejet |
|--------|-----------------|
| [Medium - Configure Ruff with pyproject.toml](https://medium.com/@gema.correa/configure-ruff-easily-with-pyproject-toml-f75914fab055) | **Article basique** sans valeur ajout√©e par rapport √† la documentation officielle. |
| [Red And Green - Ruff Python Linter](https://redandgreen.co.uk/ruff-python-linter-written-in-rust/python-code/) | **Contenu superficiel**, pr√©sentation sans profondeur technique. |
| [glukhov.org - Python Linters Guide](https://www.glukhov.org/post/2025/11/linters-for-python/) | **Guide multi-linters** moins pertinent quand Ruff remplace la plupart des outils. |

### üéØ Bonnes Pratiques SOTA 2025

1. **Ruff all-in-one** : Remplace Flake8, isort, pyupgrade, Black en un seul outil
2. **√âpinglage de version** : √âviter les faux positifs lors des mises √† jour
3. **R√®gles progressives** : Commencer par E, F, puis ajouter B, UP, S
4. **Pre-commit hooks** : Feedback imm√©diat avant commit
5. **CI stricte** : Bloquer les merges sur violations

### üìà Rem√©diation Graduelle

#### Niveau 1 - Configuration de Base (Semaine 1)
```toml
# pyproject.toml

[tool.ruff]
# Version √©pingl√©e pour reproductibilit√©
required-version = ">=0.8.0"

# Param√®tres g√©n√©raux
line-length = 88
target-version = "py39"
src = ["rekall", "tests"]

# Exclusions
exclude = [
    ".git",
    ".venv",
    "__pycache__",
    "build",
    "dist",
]

[tool.ruff.lint]
# Niveau 1: R√®gles essentielles
select = [
    "E",    # pycodestyle errors
    "F",    # Pyflakes
    "W",    # pycodestyle warnings
]

# Ignorer les r√®gles probl√©matiques
ignore = [
    "E501",  # Line too long (g√©r√© par formatter)
]

# Corrections automatiques autoris√©es
fixable = ["ALL"]
unfixable = []

[tool.ruff.format]
# Param√®tres de formatage
quote-style = "double"
indent-style = "space"
skip-magic-trailing-comma = false
line-ending = "auto"
```

#### Niveau 2 - R√®gles √âtendues (Semaine 2-3)
```toml
# pyproject.toml - Extension

[tool.ruff.lint]
select = [
    # Niveau 1
    "E", "F", "W",

    # Niveau 2 - Qualit√©
    "I",    # isort (imports)
    "N",    # pep8-naming
    "UP",   # pyupgrade
    "B",    # flake8-bugbear
    "C4",   # flake8-comprehensions
    "SIM",  # flake8-simplify

    # S√©curit√©
    "S",    # flake8-bandit (r√®gles de s√©curit√©)
]

ignore = [
    "E501",   # Line too long
    "S101",   # assert used (OK dans tests)
    "B008",   # Function call in default argument (OK avec Typer)
]

[tool.ruff.lint.per-file-ignores]
# R√®gles sp√©cifiques par fichier
"tests/**/*.py" = [
    "S101",  # assert OK dans tests
    "S105",  # Hardcoded password OK dans tests
    "S106",  # Hardcoded password OK dans tests
]
"rekall/cli.py" = [
    "B008",  # Typer utilise des defaults callable
]

[tool.ruff.lint.isort]
# Configuration isort
known-first-party = ["rekall"]
force-single-line = false
lines-after-imports = 2

[tool.ruff.lint.flake8-bandit]
# Configuration s√©curit√©
check-typed-exception = true
hardcoded-tmp-directory = ["/tmp", "/var/tmp"]
```

#### Niveau 3 - Pre-commit et CI (Mois 1)
```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.8.0  # √âpingler la version !
    hooks:
      - id: ruff
        args: [--fix, --exit-non-zero-on-fix]
      - id: ruff-format
```

```yaml
# .github/workflows/lint.yml
name: Lint

on: [push, pull_request]

jobs:
  ruff:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install Ruff
        run: pip install ruff==0.8.0  # Version √©pingl√©e

      - name: Run Ruff Linter
        run: ruff check --output-format=github .

      - name: Run Ruff Formatter
        run: ruff format --check .
```

---

## 8. Architecture et S√©paration des Couches

### üî¥ Probl√©matique Identifi√©e

> **[MOYENNE] Couche data et logique m√™l√©es**
> - `rekall/db.py` combine sch√©ma, migrations et logique
> - Difficile √† tester/√©tendre
> - D√©pendance forte √† SQLite

### üìñ Sources Consult√©es

#### ‚úÖ Sources Retenues

| Source | Raison de R√©tention |
|--------|---------------------|
| [Cosmic Python - Repository Pattern](https://www.cosmicpython.com/book/chapter_02_repository.html) | **Livre de r√©f√©rence** "Architecture Patterns with Python" par Harry Percival et Bob Gregory. Repository pattern expliqu√© avec exemples concrets. |
| [glukhov.org - Clean Architecture Python 2025](https://www.glukhov.org/post/2025/11/python-design-patterns-for-clean-architecture/) | **Article r√©cent** (Nov 2025) avec patterns modernes : Unit of Work, DI, s√©paration stricte des couches. |
| [py-clean-arch (GitHub)](https://github.com/cdddg/py-clean-arch) | **Impl√©mentation de r√©f√©rence** avec SQLAlchemy 2.0 async. Structure de projet exemplaire √† adapter. |
| [Krython - Clean Architecture Tutorial](https://www.krython.com/tutorial/python/architectural-patterns-clean-architecture) | **Tutoriel structur√©** avec diagrammes et progression p√©dagogique. Bon point d'entr√©e pour comprendre les concepts. |
| [Dev3lop - Repository Pattern](https://dev3lop.com/repository-pattern-clean-data-access-layers/) | **Focus repository** avec justifications du pattern (testabilit√©, abstraction, maintenance). |

#### ‚ùå Sources Non Retenues

| Source | Raison de Rejet |
|--------|-----------------|
| [python-clean-architecture (PyPI)](https://pypi.org/project/python-clean-architecture/) | **Package peu maintenu** (derni√®re release 2021), d√©pendances obsol√®tes. |
| [pcah/python-clean-architecture (GitHub)](https://github.com/pcah/python-clean-architecture) | **Projet inactif** (pas de commits r√©cents), approche trop complexe pour une CLI simple. |
| [fast-clean-architecture (PyPI)](https://pypi.org/project/fast-clean-architecture/) | **Scaffolding tool**, pas de documentation sur les patterns, g√©n√®re du boilerplate non adapt√©. |
| [LinkedIn - Clean Architecture Implementation](https://www.linkedin.com/pulse/implementation-clean-architecture-python-part-1-cli-watanabe) | **Article LinkedIn** sans profondeur technique suffisante, exemples incomplets. |

### üéØ Bonnes Pratiques SOTA 2025

1. **Couches distinctes** :
   - Domain (entit√©s pures, sans d√©pendances)
   - Application (use cases, orchestration)
   - Infrastructure (DB, fichiers, APIs externes)
   - Interface (CLI, API)

2. **Repository Pattern** : Abstraction du stockage pour testabilit√©
3. **Dependency Injection** : Inversion des d√©pendances
4. **Unit of Work** : Gestion transactionnelle coh√©rente

### üìà Rem√©diation Graduelle

#### Niveau 1 - Extraction des Entit√©s (Semaine 1-2)
```python
# rekall/domain/entities.py
"""
Entit√©s du domaine - AUCUNE d√©pendance externe.

Ces classes repr√©sentent les concepts m√©tier purs.
"""
from dataclasses import dataclass, field
from datetime import datetime
from typing import Optional, List
from enum import Enum


class Classification(Enum):
    PUBLIC = "public"
    INTERNAL = "internal"
    CONFIDENTIAL = "confidential"
    RESTRICTED = "restricted"


@dataclass
class Note:
    """Entit√© Note - objet m√©tier pur."""

    id: Optional[int] = None
    content: str = ""
    tags: List[str] = field(default_factory=list)
    classification: Classification = Classification.INTERNAL
    created_at: datetime = field(default_factory=datetime.now)
    updated_at: datetime = field(default_factory=datetime.now)
    retention_days: Optional[int] = None

    def is_expired(self) -> bool:
        """Logique m√©tier : la note est-elle expir√©e ?"""
        if self.retention_days is None:
            return False
        from datetime import timedelta
        expiry = self.created_at + timedelta(days=self.retention_days)
        return datetime.now() > expiry

    def contains_sensitive_data(self) -> bool:
        """Logique m√©tier : donn√©es sensibles ?"""
        return self.classification in (
            Classification.CONFIDENTIAL,
            Classification.RESTRICTED
        )
```

#### Niveau 2 - Repository Pattern (Semaine 3-4)
```python
# rekall/domain/repositories.py
"""
Interfaces des repositories - contrats abstraits.
"""
from abc import ABC, abstractmethod
from typing import List, Optional
from .entities import Note


class NoteRepository(ABC):
    """Interface abstraite pour le stockage des notes."""

    @abstractmethod
    def add(self, note: Note) -> Note:
        """Ajoute une note et retourne la note avec son ID."""
        pass

    @abstractmethod
    def get(self, note_id: int) -> Optional[Note]:
        """R√©cup√®re une note par son ID."""
        pass

    @abstractmethod
    def get_all(self, limit: int = 100) -> List[Note]:
        """R√©cup√®re toutes les notes."""
        pass

    @abstractmethod
    def search(self, query: str, limit: int = 50) -> List[Note]:
        """Recherche full-text dans les notes."""
        pass

    @abstractmethod
    def update(self, note: Note) -> Note:
        """Met √† jour une note existante."""
        pass

    @abstractmethod
    def delete(self, note_id: int) -> bool:
        """Supprime une note. Retourne True si supprim√©e."""
        pass

    @abstractmethod
    def purge_expired(self) -> int:
        """Purge les notes expir√©es. Retourne le nombre purg√©."""
        pass


# rekall/infrastructure/sqlite_repository.py
"""
Impl√©mentation SQLite du repository.
"""
import sqlite3
from typing import List, Optional
from datetime import datetime

from rekall.domain.entities import Note, Classification
from rekall.domain.repositories import NoteRepository


class SQLiteNoteRepository(NoteRepository):
    """Impl√©mentation SQLite du NoteRepository."""

    def __init__(self, db_path: str):
        self.db_path = db_path
        self._connection: Optional[sqlite3.Connection] = None

    @property
    def connection(self) -> sqlite3.Connection:
        if self._connection is None:
            self._connection = sqlite3.connect(self.db_path)
            self._connection.row_factory = sqlite3.Row
        return self._connection

    def _row_to_note(self, row: sqlite3.Row) -> Note:
        """Convertit une ligne DB en entit√© Note."""
        return Note(
            id=row["id"],
            content=row["content"],
            tags=row["tags"].split(",") if row["tags"] else [],
            classification=Classification(row["classification"]),
            created_at=datetime.fromisoformat(row["created_at"]),
            updated_at=datetime.fromisoformat(row["updated_at"]),
            retention_days=row["retention_days"],
        )

    def add(self, note: Note) -> Note:
        cursor = self.connection.execute(
            """
            INSERT INTO notes (content, tags, classification, created_at, updated_at, retention_days)
            VALUES (?, ?, ?, ?, ?, ?)
            """,
            (
                note.content,
                ",".join(note.tags),
                note.classification.value,
                note.created_at.isoformat(),
                note.updated_at.isoformat(),
                note.retention_days,
            )
        )
        self.connection.commit()
        note.id = cursor.lastrowid
        return note

    def get(self, note_id: int) -> Optional[Note]:
        cursor = self.connection.execute(
            "SELECT * FROM notes WHERE id = ?",
            (note_id,)
        )
        row = cursor.fetchone()
        return self._row_to_note(row) if row else None

    def search(self, query: str, limit: int = 50) -> List[Note]:
        cursor = self.connection.execute(
            """
            SELECT n.* FROM notes n
            JOIN notes_fts ON n.id = notes_fts.rowid
            WHERE notes_fts MATCH ?
            ORDER BY rank
            LIMIT ?
            """,
            (query, limit)
        )
        return [self._row_to_note(row) for row in cursor.fetchall()]

    # ... autres m√©thodes ...
```

#### Niveau 3 - Use Cases et DI (Mois 1-2)
```python
# rekall/application/use_cases.py
"""
Use cases - orchestration de la logique m√©tier.
"""
from dataclasses import dataclass
from typing import List, Optional

from rekall.domain.entities import Note
from rekall.domain.repositories import NoteRepository
from rekall.application.validators import NoteValidator


@dataclass
class CreateNoteUseCase:
    """Use case : Cr√©ation d'une note."""

    repository: NoteRepository
    validator: NoteValidator

    def execute(self, content: str, **kwargs) -> Note:
        """
        Cr√©e une nouvelle note apr√®s validation.

        Raises:
            ValidationError: Si le contenu est invalide
        """
        # Validation
        validated = self.validator.validate_content(content)

        # Cr√©ation de l'entit√©
        note = Note(
            content=validated,
            **kwargs
        )

        # Persistance
        return self.repository.add(note)


@dataclass
class SearchNotesUseCase:
    """Use case : Recherche de notes."""

    repository: NoteRepository
    validator: NoteValidator

    def execute(self, query: str, limit: int = 50) -> List[Note]:
        """
        Recherche des notes correspondant √† la requ√™te.
        """
        # Validation et sanitization
        safe_query = self.validator.sanitize_search_query(query)

        # Recherche
        return self.repository.search(safe_query, limit)


# rekall/infrastructure/container.py
"""
Conteneur d'injection de d√©pendances.
"""
from dataclasses import dataclass
from pathlib import Path

from rekall.domain.repositories import NoteRepository
from rekall.infrastructure.sqlite_repository import SQLiteNoteRepository
from rekall.application.use_cases import CreateNoteUseCase, SearchNotesUseCase
from rekall.application.validators import NoteValidator


@dataclass
class Container:
    """Conteneur DI simple."""

    db_path: Path

    @property
    def note_repository(self) -> NoteRepository:
        return SQLiteNoteRepository(str(self.db_path))

    @property
    def note_validator(self) -> NoteValidator:
        return NoteValidator()

    @property
    def create_note(self) -> CreateNoteUseCase:
        return CreateNoteUseCase(
            repository=self.note_repository,
            validator=self.note_validator,
        )

    @property
    def search_notes(self) -> SearchNotesUseCase:
        return SearchNotesUseCase(
            repository=self.note_repository,
            validator=self.note_validator,
        )
```

#### Structure de Projet Cible
```
rekall/
‚îú‚îÄ‚îÄ domain/                 # Couche Domaine (0 d√©pendances)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ entities.py         # Entit√©s m√©tier
‚îÇ   ‚îî‚îÄ‚îÄ repositories.py     # Interfaces abstraites
‚îÇ
‚îú‚îÄ‚îÄ application/            # Couche Application
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ use_cases.py        # Cas d'utilisation
‚îÇ   ‚îî‚îÄ‚îÄ validators.py       # Validation m√©tier
‚îÇ
‚îú‚îÄ‚îÄ infrastructure/         # Couche Infrastructure
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ sqlite_repository.py
‚îÇ   ‚îú‚îÄ‚îÄ crypto.py           # Chiffrement
‚îÇ   ‚îî‚îÄ‚îÄ container.py        # DI
‚îÇ
‚îú‚îÄ‚îÄ interface/              # Couche Interface
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ cli.py              # Commandes Typer
‚îÇ
‚îî‚îÄ‚îÄ migrations/             # Migrations DB
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îî‚îÄ‚îÄ versions/
```

---

## 9. Duplication de Code et Principe DRY

### üî¥ Probl√©matique Identifi√©e

> **[MOYENNE] Duplication de la s√©rialisation JSON**
> - Les exports JSON sont impl√©ment√©s deux fois (`exporters.py` L90-109 et `archive.py` L91-145)
> - M√™me mapping champ-par-champ dupliqu√©
> - Risque d'√©carts de format entre export simple et archive compress√©e
> - Fichiers concern√©s: `rekall/exporters.py`, `rekall/archive.py`

### üìñ Sources Consult√©es

#### ‚úÖ Sources Retenues

| Source | Raison de R√©tention |
|--------|---------------------|
| [CodeSignal - Applying DRY Principle in Python](https://codesignal.com/learn/courses/applying-clean-code-principles-in-python/lessons/applying-the-dry-principle-in-python) | **Cours structur√©** avec exemples concrets d'extraction de fonctions. Techniques directement applicables. |
| [Earth Lab - DRY Code and Modularity](https://earthdatascience.org/courses/intro-to-earth-data-science/write-efficient-python-code/intro-to-clean-code/dry-modular-code/) | **Guide acad√©mique** avec 3 strat√©gies cl√©s : fonctions, boucles, conditionnels. Approche p√©dagogique claire. |
| [Pydantic Serialization Docs](https://docs.pydantic.dev/latest/concepts/serialization/) | **Documentation officielle** pour les patterns `model_dump()` et s√©rialisation JSON. R√©f√©rence authoritative. |
| [Tom Augspurger - Serializing Dataclasses](https://tomaugspurger.net/posts/serializing-dataclasses/) | **Article technique** comparant `asdict()` vs custom serializers. Recommandations pratiques pour dataclasses. |
| [Hrekov - Python Data Serialization 2025](https://hrekov.com/blog/python-data-serialization-2025) | **Panorama 2025** des alternatives (msgspec, cattrs, pyserde). Contexte sur l'√©volution de l'√©cosyst√®me. |

#### ‚ùå Sources Non Retenues

| Source | Raison de Rejet |
|--------|-----------------|
| [Wikipedia - DRY Principle](https://en.wikipedia.org/wiki/Don't_repeat_yourself) | **Trop g√©n√©raliste**, d√©finition sans exemples de code Python. |
| [Gazar - Embracing DRY Principle](https://gazar.dev/clean-code/embracing-the-dry-principle-in-programming) | **Exemples multi-langages**, pas de focus Python sp√©cifique. |
| [leehanchung - Pydantic Performance Spaghetti](https://leehanchung.github.io/blogs/2025/07/03/pydantic-is-all-you-need-for-performance-spaghetti/) | **Article critique** utile pour le contexte mais anti-Pydantic extr√™me. Bias visible. |
| [PixelFreeStudio - DRY Best Practices](https://blog.pixelfreestudio.com/best-practices-for-writing-dry-dont-repeat-yourself-code/) | **Contenu g√©n√©rique**, pas d'exemples Python concrets. |

### üéØ Bonnes Pratiques SOTA 2025

1. **Single Source of Truth** : Une seule fonction de s√©rialisation pour un type de donn√©es
2. **S√©parer validation et s√©rialisation** : Pydantic aux fronti√®res, dataclass en interne
3. **Module utilitaire d√©di√©** : Centraliser les conversions dans un fichier `serializers.py`
4. **Tests unitaires** : Chaque fonction de conversion doit avoir ses tests
5. **Documentation du sch√©ma** : Documenter le format JSON attendu

### üìà Rem√©diation Graduelle

#### Niveau 1 - Fonction Partag√©e Basique (30 min) ‚úÖ ESSENTIEL
```python
# rekall/utils.py (ou ajouter √† un fichier existant)
from dataclasses import asdict
from datetime import datetime
from typing import Any, Dict

def entry_to_dict(entry) -> Dict[str, Any]:
    """
    Convertit une Entry en dictionnaire s√©rialisable JSON.

    Source unique de v√©rit√© pour la s√©rialisation des entr√©es.
    Utilis√©e par exporters.py ET archive.py.
    """
    data = asdict(entry)

    # Conversion des types non-JSON
    for key, value in data.items():
        if isinstance(value, datetime):
            data[key] = value.isoformat()

    return data


def dict_to_entry(data: Dict[str, Any], entry_class):
    """
    Reconstruit une Entry depuis un dictionnaire JSON.

    Source unique de v√©rit√© pour la d√©s√©rialisation.
    """
    # Conversion des dates ISO -> datetime
    for key in ['created_at', 'updated_at', 'recalled_at']:
        if key in data and isinstance(data[key], str):
            data[key] = datetime.fromisoformat(data[key])

    return entry_class(**data)
```

```python
# rekall/exporters.py - Modification
from rekall.utils import entry_to_dict

def export_to_json(entries, output_path):
    data = [entry_to_dict(e) for e in entries]
    # ... reste du code
```

```python
# rekall/archive.py - Modification
from rekall.utils import entry_to_dict, dict_to_entry

def create_archive(entries, output_path):
    data = [entry_to_dict(e) for e in entries]
    # ... reste du code
```

#### Niveau 2 - Module Serializers D√©di√© (1h) üëç RECOMMAND√â
```python
# rekall/serializers.py
"""
Module de s√©rialisation centralis√©.

Toute conversion Entry <-> dict/JSON passe par ce module.
√âvite la duplication et garantit la coh√©rence des formats.
"""
from dataclasses import asdict, fields
from datetime import datetime
from typing import Any, Dict, List, Type, TypeVar
import json

T = TypeVar('T')

class EntrySerializer:
    """Serializer pour les objets Entry."""

    # Champs √† traiter comme des dates
    DATE_FIELDS = {'created_at', 'updated_at', 'recalled_at'}

    # Champs sensibles √† masquer dans certains exports
    SENSITIVE_FIELDS = {'api_key', 'password', 'token'}

    @classmethod
    def to_dict(cls, entry, mask_sensitive: bool = False) -> Dict[str, Any]:
        """Convertit une Entry en dict."""
        data = asdict(entry)

        for key, value in list(data.items()):
            # Dates -> ISO string
            if isinstance(value, datetime):
                data[key] = value.isoformat()

            # Masquage optionnel des champs sensibles
            if mask_sensitive and key in cls.SENSITIVE_FIELDS:
                data[key] = "***MASKED***"

        return data

    @classmethod
    def from_dict(cls, data: Dict[str, Any], entry_class: Type[T]) -> T:
        """Reconstruit une Entry depuis un dict."""
        # Copie pour ne pas modifier l'original
        data = data.copy()

        # Conversion des dates
        for key in cls.DATE_FIELDS:
            if key in data and isinstance(data[key], str):
                data[key] = datetime.fromisoformat(data[key])

        # Ne garder que les champs valides pour la dataclass
        valid_fields = {f.name for f in fields(entry_class)}
        data = {k: v for k, v in data.items() if k in valid_fields}

        return entry_class(**data)

    @classmethod
    def to_json(cls, entries: List, indent: int = 2) -> str:
        """S√©rialise une liste d'entries en JSON."""
        data = [cls.to_dict(e) for e in entries]
        return json.dumps(data, indent=indent, ensure_ascii=False)

    @classmethod
    def from_json(cls, json_str: str, entry_class: Type[T]) -> List[T]:
        """D√©s√©rialise du JSON en liste d'entries."""
        data = json.loads(json_str)
        return [cls.from_dict(d, entry_class) for d in data]
```

#### Niveau 3 - Pydantic Models avec Serdes (Refactoring majeur) ‚ö†Ô∏è OVERKILL
```python
# rekall/models.py - Remplacement complet par Pydantic
# ‚ö†Ô∏è N√©cessite de modifier TOUS les usages de Entry
from pydantic import BaseModel, Field
from datetime import datetime
from typing import Optional

class Entry(BaseModel):
    """Entry avec s√©rialisation Pydantic native."""

    id: Optional[int] = None
    content: str
    created_at: datetime = Field(default_factory=datetime.now)
    updated_at: datetime = Field(default_factory=datetime.now)

    model_config = {
        "json_encoders": {
            datetime: lambda v: v.isoformat()
        }
    }

# Usage:
# entry.model_dump()  # -> dict
# entry.model_dump_json()  # -> JSON string
# Entry.model_validate(data)  # -> Entry from dict
```

**Pourquoi c'est overkill :** Le sch√©ma `Entry` est stable depuis longtemps. Migrer vers Pydantic n√©cessite de modifier tous les fichiers qui cr√©ent/manipulent des Entry. Pour un gain minime sur un sch√©ma qui ne change pas, c'est du refactoring pour le plaisir du refactoring.

---

## 10. CLI Monolithique et Modularisation

### üî¥ Probl√©matique Identifi√©e

> **[MOYENNE] CLI concentrant ~2.7k lignes**
> - Configuration, acc√®s base, TUI, int√©grations et commandes m√©tier m√©lang√©s
> - Navigation et d√©couplage difficiles
> - Fichier concern√©: `rekall/cli.py`

### üìñ Sources Consult√©es

#### ‚úÖ Sources Retenues

| Source | Raison de R√©tention |
|--------|---------------------|
| [PyTutorial - Typer Subcommands and Modular CLI](https://pytutorial.com/python-typer-subcommands-and-modular-cli/) | **Guide pratique Typer** avec structure de projet recommand√©e et `add_typer()` pour grouper les commandes. |
| [Real Python - Click Extensible CLI](https://realpython.com/python-click/) | **Tutoriel approfondi** sur les nested commands et l'architecture modulaire Click (base de Typer). |
| [Better Stack - Click Explained](https://betterstack.com/community/guides/scaling-python/click-explained/) | **Guide complet** avec patterns de composition et lazy loading pour grandes CLIs. |
| [Hitchhiker's Guide - Project Structure](https://docs.python-guide.org/writing/structure/) | **R√©f√©rence Python** sur la structuration de projets. Principes applicables aux CLIs. |
| [Qodo - 8 Python Refactoring Techniques](https://www.qodo.ai/blog/8-python-code-refactoring-techniques-tools-practices/) | **Guide refactoring** avec outils (Rope, PyCharm) et best practices pour extraire du code. |

#### ‚ùå Sources Non Retenues

| Source | Raison de Rejet |
|--------|-----------------|
| [CodeRivers - Mastering Typer](https://coderivers.org/blog/typer-python/) | **Contenu basique** r√©p√©tant la documentation officielle sans valeur ajout√©e. |
| [djamware - Build CLI with Typer](https://www.djamware.com/post/692d8641e6e2a42c2b84c3c1/build-powerful-commandline-tools-in-python-using-typer) | **Tutoriel d√©butant**, pas de patterns avanc√©s pour grandes CLIs. |
| [jsschools - Python CLI Development](https://jsschools.com/python/python-cli-development-top-libraries-for-building/) | **Comparatif superficiel** de biblioth√®ques sans profondeur technique. |
| [Khan Academy - Great Python Refactor](https://blog.khanacademy.org/the-great-python-refactor-of-2017-and-also-2018/) | **Contexte int√©ressant** mais sp√©cifique √† leur codebase, peu applicable directement. |

### üéØ Bonnes Pratiques SOTA 2025

1. **S√©paration des concerns** : Code CLI s√©par√© de la logique m√©tier
2. **Sous-commandes modulaires** : Un fichier par groupe de commandes li√©es
3. **Lazy loading** : Charger les d√©pendances lourdes uniquement si n√©cessaire
4. **Configuration centralis√©e** : Un module d√©di√© pour init DB/config
5. **Tests isol√©s** : Chaque module de commandes testable ind√©pendamment

### üìà Rem√©diation Graduelle

#### Niveau 1 - Extraction des Helpers (1h) üëç RECOMMAND√â
```python
# rekall/config.py (nouveau fichier)
"""
Configuration et initialisation centralis√©es.

Extrait de cli.py pour r√©duire le bruit.
"""
from pathlib import Path
from typing import Optional
import os

# Constantes de configuration
DEFAULT_DB_NAME = "rekall.db"
DEFAULT_CONFIG_DIR = Path.home() / ".rekall"

_db_connection = None
_config = None


def get_config_dir() -> Path:
    """Retourne le r√©pertoire de configuration."""
    config_dir = Path(os.environ.get("REKALL_CONFIG_DIR", DEFAULT_CONFIG_DIR))
    config_dir.mkdir(parents=True, exist_ok=True)
    return config_dir


def get_db_path() -> Path:
    """Retourne le chemin de la base de donn√©es."""
    return get_config_dir() / DEFAULT_DB_NAME


def get_db_connection():
    """Retourne une connexion √† la base de donn√©es (singleton)."""
    global _db_connection
    if _db_connection is None:
        import sqlite3
        _db_connection = sqlite3.connect(get_db_path())
        _db_connection.row_factory = sqlite3.Row
    return _db_connection


def init_db():
    """Initialise le sch√©ma de la base de donn√©es."""
    conn = get_db_connection()
    # ... migrations et cr√©ation de tables
    return conn
```

```python
# rekall/cli.py - Simplification
from rekall.config import get_db_connection, init_db, get_config_dir

# Au lieu de 200 lignes d'init, maintenant:
app = typer.Typer()

@app.callback()
def main():
    """Rekall - Base de connaissances personnelle."""
    init_db()

# ... commandes uniquement
```

#### Niveau 2 - Sous-commandes Modulaires (2-3h) üü° OPTIONNEL
```
rekall/
‚îú‚îÄ‚îÄ cli.py              # App principale + callback
‚îú‚îÄ‚îÄ config.py           # Configuration (niveau 1)
‚îú‚îÄ‚îÄ commands/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ entries.py      # add, edit, delete, show
‚îÇ   ‚îú‚îÄ‚îÄ search.py       # search, recall
‚îÇ   ‚îú‚îÄ‚îÄ export.py       # export, archive, restore
‚îÇ   ‚îî‚îÄ‚îÄ integrations.py # install-*, configure-*
```

```python
# rekall/commands/export.py
import typer
from rekall.config import get_db_connection
from rekall.serializers import EntrySerializer

app = typer.Typer(help="Commandes d'export et d'archivage")

@app.command()
def json(output: Path, mask_pii: bool = False):
    """Exporte les entr√©es en JSON."""
    # ...

@app.command()
def archive(output: Path):
    """Cr√©e une archive compress√©e."""
    # ...

@app.command()
def restore(archive_path: Path):
    """Restaure depuis une archive."""
    # ...
```

```python
# rekall/cli.py - App principale
import typer
from rekall.commands import entries, search, export, integrations

app = typer.Typer()

# Enregistrement des sous-commandes
app.add_typer(entries.app, name="entry")
app.add_typer(search.app, name="search")
app.add_typer(export.app, name="export")
app.add_typer(integrations.app, name="integration")

# Commandes de niveau racine (raccourcis)
@app.command()
def add(content: str):
    """Raccourci pour 'entry add'."""
    entries.add(content)
```

#### Niveau 3 - Architecture Plugins Typer (Demi-journ√©e+) ‚ö†Ô∏è OVERKILL
```python
# rekall/plugin_loader.py
# ‚ö†Ô∏è Over-engineering pour une CLI de ~15 commandes
import importlib
import pkgutil
from pathlib import Path

def discover_commands(package_path: str = "rekall.commands"):
    """D√©couvre et charge automatiquement les modules de commandes."""
    package = importlib.import_module(package_path)

    for _, name, _ in pkgutil.iter_modules(package.__path__):
        module = importlib.import_module(f"{package_path}.{name}")
        if hasattr(module, 'app'):
            yield name, module.app


# Dans cli.py:
for name, sub_app in discover_commands():
    app.add_typer(sub_app, name=name)
```

**Pourquoi c'est overkill :** Rekall a ~15 commandes. Un syst√®me de d√©couverte automatique de plugins est utile quand tu as 50+ commandes ou des plugins tiers. Pour 15 commandes, `add_typer()` explicite est plus clair et debuggable.

---

## 11. Code Mort et Int√©grations Non Raccord√©es

### üî¥ Probl√©matique Identifi√©e

> **[MOYENNE] Code inactif / non raccord√©**
> - Installateurs d'int√©grations (Copilot, Windsurf, Cline, Aider, Continue) d√©finis mais inaccessibles
> - Aucun appel r√©f√©renc√© hors du module `integrations/__init__.py`
> - Capacit√©s pr√©sentes mais non expos√©es depuis la CLI/TUI
> - Fichier concern√©: `rekall/integrations/__init__.py` (L442-519)

### üìñ Sources Consult√©es

#### ‚úÖ Sources Retenues

| Source | Raison de R√©tention |
|--------|---------------------|
| [Vulture (GitHub)](https://github.com/jendrikseipp/vulture) | **Outil de r√©f√©rence** pour la d√©tection de code mort Python. Analyse AST, confidence levels, whitelists. Maintenu activement. |
| [deadcode (PyPI)](https://pypi.org/project/deadcode/) | **Alternative moderne** avec plus de r√®gles que Vulture, option `--fix` pour suppression automatique, int√©gration avec ruff. |
| [Adam Johnson - Django Vulture](https://adamj.eu/tech/2023/07/12/django-clean-up-unused-code-vulture/) | **Guide pratique** avec workflow complet : ex√©cution, whitelisting, int√©gration CI. Applicable au-del√† de Django. |
| [OpenStack Stevedore](https://docs.openstack.org/stevedore/latest/user/essays/pycon2013.html) | **R√©f√©rence** pour les architectures de plugins Python avec entry points. Patterns √©prouv√©s en production. |
| [Pluggy (pytest)](https://medium.com/@garzia.luke/developing-plugin-architecture-with-pluggy-8eb7bdba3303) | **Framework de plugins** utilis√© par pytest. L√©ger, bien document√©, adapt√© aux hooks d'extension. |

#### ‚ùå Sources Non Retenues

| Source | Raison de Rejet |
|--------|-----------------|
| [witve.com - Mastering Vulture](https://witve.com/codes/mastering-vulture-the-ultimate-guide-to-finding-dead-code-in-python/) | **Site de qualit√© douteuse**, contenu probablement g√©n√©r√©, pas de valeur technique ajout√©e. |
| [Medium - Dead code detection](https://medium.com/@kinjaldave299/dead-code-detection-in-python-6bbec093b86b) | **Article basique** r√©p√©tant la doc Vulture sans insights. |
| [rj722 - Coverage for dead code](https://rj722.github.io/articles/18/why-use-coverage-to-find-which-python-code-is-run) | **Approche diff√©rente** (runtime vs static). Utile mais compl√©mentaire, pas principal. |
| [vinnie.work - Python Plugin Pattern](https://www.vinnie.work/blog/2021-02-16-python-plugin-pattern) | **Article de 2021**, patterns moins modernes que Stevedore/Pluggy. |

### üéØ Bonnes Pratiques SOTA 2025

1. **D√©tection automatique** : Vulture/deadcode en CI pour d√©tecter le code mort
2. **Documenter l'intention** : Si le code est intentionnellement non utilis√© (API future), le marquer
3. **Registre explicite** : Les extensions doivent √™tre enregistr√©es et accessibles
4. **Supprimer ou exposer** : Pas de code "zombie" - soit il sert, soit il dispara√Æt
5. **Whitelists versionn√©es** : Maintenir les exceptions Vulture dans le repo

### üìà Rem√©diation Graduelle

#### Niveau 1 - Vulture en CI (15 min) ‚úÖ ESSENTIEL
```yaml
# .github/workflows/lint.yml (ajout)
- name: Check dead code
  run: |
    pip install vulture
    vulture rekall/ --min-confidence 80
```

```toml
# pyproject.toml
[tool.vulture]
min_confidence = 80
paths = ["rekall"]
exclude = ["tests/", "*.pyi"]
```

```python
# vulture_whitelist.py
# Code intentionnellement non utilis√© localement mais expos√© via API
from rekall.integrations import (
    install_copilot,    # Installateur pour VS Code Copilot
    install_windsurf,   # Installateur pour Windsurf IDE
    install_cline,      # Installateur pour Cline
    install_aider,      # Installateur pour Aider
    install_continue,   # Installateur pour Continue
)

# Ces fonctions sont dans le registre INTEGRATIONS
# et seront expos√©es via CLI dans une future version
```

#### Niveau 2 - Exposer les Int√©grations (1-2h) üëç RECOMMAND√â
```python
# rekall/cli.py - Ajout de commandes pour les int√©grations

from rekall.integrations import INTEGRATIONS

@app.command("list-integrations")
def list_integrations():
    """Liste les int√©grations disponibles."""
    from rich.table import Table
    from rich.console import Console

    console = Console()
    table = Table(title="Int√©grations Disponibles")
    table.add_column("Nom", style="cyan")
    table.add_column("Description")
    table.add_column("Status")

    for name, integration in INTEGRATIONS.items():
        status = "‚úÖ Install√©" if integration.is_installed() else "‚ùå Non install√©"
        table.add_row(name, integration.description, status)

    console.print(table)


@app.command("install-integration")
def install_integration(
    name: str = typer.Argument(..., help="Nom de l'int√©gration")
):
    """Installe une int√©gration IDE/agent."""
    if name not in INTEGRATIONS:
        typer.echo(f"‚ùå Int√©gration inconnue: {name}")
        typer.echo(f"Disponibles: {', '.join(INTEGRATIONS.keys())}")
        raise typer.Exit(1)

    integration = INTEGRATIONS[name]
    typer.echo(f"üì¶ Installation de {name}...")

    try:
        integration.install()
        typer.echo(f"‚úÖ {name} install√© avec succ√®s!")
    except Exception as e:
        typer.echo(f"‚ùå Erreur: {e}")
        raise typer.Exit(1)
```

```python
# rekall/integrations/__init__.py - Am√©lioration du registre
from dataclasses import dataclass
from typing import Callable, Dict, Optional
from pathlib import Path

@dataclass
class Integration:
    """D√©finition d'une int√©gration."""
    name: str
    description: str
    install_fn: Callable[[], None]
    check_fn: Callable[[], bool]
    config_path: Optional[Path] = None

    def install(self):
        """Installe l'int√©gration."""
        self.install_fn()

    def is_installed(self) -> bool:
        """V√©rifie si l'int√©gration est install√©e."""
        return self.check_fn()


# Registre unifi√©
INTEGRATIONS: Dict[str, Integration] = {
    "copilot": Integration(
        name="copilot",
        description="GitHub Copilot pour VS Code",
        install_fn=_install_copilot,
        check_fn=_check_copilot_installed,
        config_path=Path.home() / ".config" / "github-copilot",
    ),
    "windsurf": Integration(
        name="windsurf",
        description="Windsurf IDE",
        install_fn=_install_windsurf,
        check_fn=_check_windsurf_installed,
    ),
    # ... autres int√©grations
}
```

#### Niveau 3 - Syst√®me de Plugins Dynamique (Demi-journ√©e) üü° OPTIONNEL
```python
# rekall/plugins/__init__.py
# Utiliser stevedore pour les plugins tiers
from stevedore import ExtensionManager

def load_integration_plugins():
    """Charge les plugins d'int√©gration via entry points."""
    mgr = ExtensionManager(
        namespace='rekall.integrations',
        invoke_on_load=False,
    )

    for ext in mgr:
        INTEGRATIONS[ext.name] = ext.plugin


# setup.py / pyproject.toml du plugin tiers:
# [project.entry-points."rekall.integrations"]
# my_ide = "rekall_myide:MyIDEIntegration"
```

**Quand c'est utile :** Si tu veux permettre √† d'autres d√©veloppeurs de cr√©er des plugins d'int√©gration installables via pip. Pour usage personnel, le registre statique (Niveau 2) suffit.

### Points Positifs Identifi√©s

L'audit a √©galement relev√© des √©l√©ments positifs √† pr√©server :

1. **Registre unifi√© `INTEGRATIONS`** : Le pattern de registre est d√©j√† en place, il suffit de l'exposer via la CLI.

2. **Regex pour champs sensibles** : Les fonctions d'export balisent d√©j√† les champs sensibles, facilitant l'extension future des contr√¥les de fuite.

```python
# D√©j√† pr√©sent dans exporters.py L11-37 - √Ä conserver et √©tendre
SENSITIVE_PATTERNS = {
    "api_key": r"[a-zA-Z0-9]{32,}",
    "password": r"password\s*[:=]\s*\S+",
    # ...
}
```

---

## 12. Observabilit√© et Gestion d'Erreurs

### üî¥ Probl√©matique Identifi√©e

> **[MOYENNE] Exceptions silencieuses masquant les d√©faillances**
> - Plusieurs blocs `except Exception` sans journalisation ni remont√©e
> - Erreurs de migration/config invisibles pour l'utilisateur
> - Fichiers concern√©s: `cli.py:172-188`, `config.py:105-123`, `paths.py:247-280`

### üìñ Sources Consult√©es

#### ‚úÖ Sources Retenues

| Source | Raison de R√©tention |
|--------|---------------------|
| [PEP 760 - No More Bare Excepts](https://peps.python.org/pep-0760/) | **R√©f√©rence officielle Python** proposant l'interdiction des `except:` nus. Confirme que c'est un anti-pattern reconnu. |
| [Qodo - 6 Best Practices Python Exceptions](https://www.qodo.ai/blog/6-best-practices-for-python-exception-handling/) | **Guide complet 2025** avec exemples concrets : exceptions sp√©cifiques, try blocks courts, custom exceptions. |
| [Real Python - Diabolical Antipattern](https://realpython.com/the-most-diabolical-python-antipattern/) | **Article de r√©f√©rence** expliquant pourquoi `except Exception` silencieux est le pire antipattern Python. |
| [Typer - Exceptions](https://typer.tiangolo.com/tutorial/exceptions/) | **Documentation officielle Typer** pour la gestion d'erreurs en CLI avec Rich et codes de sortie. |
| [BetterStack - Loguru Guide](https://betterstack.com/community/guides/logging/loguru/) | **Guide complet Loguru** avec backtrace enrichi, exception logging, configuration production. |
| [Structlog - Logging Best Practices](https://www.structlog.org/en/stable/logging-best-practices.html) | **Documentation officielle structlog** avec patterns pour structured logging et JSON output. |

#### ‚ùå Sources Non Retenues

| Source | Raison de Rejet |
|--------|-----------------|
| [Eduonix - Error Handling](https://blog.eduonix.com/2025/05/error-handling-in-python-master-try-except-and-best-practices/) | **Article g√©n√©raliste** sans insights sp√©cifiques pour CLI ou logging avanc√©. |
| [Medium - Divyansh Patel](https://medium.com/@divyansh9144/effective-error-handling-in-python-navigating-best-practices-and-common-pitfalls-c8f1680611c5) | **Contenu basique** r√©p√©tant la doc Python sans valeur ajout√©e. |
| [Trajectory Hub - Python Try](https://trajdash.usc.edu/python-try) | **Site acad√©mique** peu adapt√© au contexte professionnel, exemples trop simples. |
| [Jerry NSH - Stop Using Exceptions](https://jerrynsh.com/stop-using-exceptions-like-this-in-python/) | **Article blog personnel**, certains conseils discutables (pas de sources). |

### üéØ Bonnes Pratiques SOTA 2025

1. **Exceptions sp√©cifiques** : Capturer `FileNotFoundError`, `TOMLDecodeError`, `sqlite3.Error` plut√¥t que `Exception`
2. **Logging syst√©matique** : `logger.exception()` pour traceback complet, `logger.error()` pour messages simples
3. **Feedback utilisateur** : Messages Rich/Typer avec suggestions de rem√©diation
4. **Try blocks courts** : Minimiser le code dans le try pour identifier pr√©cis√©ment l'origine
5. **Ne jamais silencer** : Si on catch, on log ou on remonte (re-raise)

### üìà Rem√©diation Graduelle

#### Niveau 1 - Exceptions Cibl√©es + Logging (30 min) ‚úÖ ESSENTIEL
```python
# AVANT (cli.py L172-188) - Mauvais
try:
    schema_info = get_schema()
except Exception:
    schema_info = {}  # Silencieux !

# APR√àS - Bon
import logging
logger = logging.getLogger(__name__)

try:
    schema_info = get_schema()
except sqlite3.Error as e:
    logger.exception("Erreur lecture sch√©ma DB")
    schema_info = {}
except FileNotFoundError as e:
    logger.warning("Base de donn√©es non trouv√©e: %s", e)
    schema_info = {}
```

```python
# AVANT (config.py L105-123) - Mauvais
try:
    with open(config_path) as f:
        return tomllib.loads(f.read())
except Exception:
    return {}  # Config corrompue = silencieux !

# APR√àS - Bon
try:
    with open(config_path) as f:
        return tomllib.loads(f.read())
except FileNotFoundError:
    logger.info("Config non trouv√©e, utilisation des d√©fauts")
    return {}
except tomllib.TOMLDecodeError as e:
    logger.error("Config TOML invalide: %s", e)
    typer.echo(f"‚ö†Ô∏è  Config corrompue: {config_path}", err=True)
    typer.echo("   Suggestion: v√©rifiez la syntaxe ou supprimez le fichier", err=True)
    return {}
```

#### Niveau 2 - Rich/Typer Feedback (1h) üëç RECOMMAND√â
```python
from rich.console import Console
from rich.panel import Panel

console = Console(stderr=True)

def handle_config_error(path: Path, error: Exception) -> dict:
    """G√®re les erreurs de config avec feedback utilisateur."""
    if isinstance(error, FileNotFoundError):
        return {}  # Normal au premier lancement

    if isinstance(error, tomllib.TOMLDecodeError):
        console.print(Panel(
            f"[red]Erreur de syntaxe TOML[/red]\n\n"
            f"Fichier: {path}\n"
            f"Erreur: {error}\n\n"
            f"[yellow]Suggestions:[/yellow]\n"
            f"‚Ä¢ V√©rifiez les guillemets et crochets\n"
            f"‚Ä¢ Utilisez un validateur TOML en ligne\n"
            f"‚Ä¢ Supprimez le fichier pour r√©g√©n√©rer les d√©fauts",
            title="‚ö†Ô∏è  Configuration invalide",
            border_style="red"
        ))
        return {}

    # Erreur inattendue - on log et on propage
    logger.exception("Erreur config inattendue")
    raise
```

#### Niveau 3 - Structured Logging avec Loguru (2h) üü° OPTIONNEL
```python
from loguru import logger
import sys

# Configuration Loguru pour CLI
logger.remove()  # Supprimer handler par d√©faut
logger.add(
    sys.stderr,
    format="<level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
    level="WARNING",  # Seulement warnings+ en CLI
    backtrace=True,
    diagnose=False,  # D√©sactiver en prod (s√©curit√©)
)

# Log fichier pour debug
logger.add(
    "~/.rekall/debug.log",
    rotation="1 MB",
    retention="7 days",
    level="DEBUG",
    format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {name}:{line} | {message}",
)

# Usage
try:
    config = load_config()
except Exception:
    logger.exception("√âchec chargement config")
    # Loguru capture automatiquement le traceback + variables locales
```

**Pourquoi c'est optionnel :** Pour une CLI locale, `logging` stdlib + Rich suffit. Loguru est utile si tu as besoin d'agr√©ger des logs ou de debug des probl√®mes complexes.

---

## 13. Persistance de Configuration (Int√©grit√© et Concurrence)

### üî¥ Probl√©matique Identifi√©e

> **[MOYENNE] √âcriture config non atomique et non s√©curis√©e**
> - √âcriture manuelle sans lib TOML (risque d'√©chappement)
> - Pas d'√©criture atomique (crash = fichier partiel)
> - Retourne bool√©en silencieux sans feedback
> - Fichier concern√©: `config.py:125-167`

### üìñ Sources Consult√©es

#### ‚úÖ Sources Retenues

| Source | Raison de R√©tention |
|--------|---------------------|
| [Real Python - Python and TOML](https://realpython.com/python-toml/) | **Guide complet 2025** sur tomllib/tomli/tomli-w avec patterns de lecture/√©criture. |
| [tomli-w (PyPI)](https://pypi.org/project/tomli-w/) | **Documentation officielle** du compagnon d'√©criture pour tomllib, API simple et TOML 1.0 compliant. |
| [atomicwrites (GitHub)](https://github.com/untitaker/python-atomicwrites) | **R√©f√©rence pour atomic writes** - bien que maintenance inactive, le pattern reste valide. |
| [gocept - Reliable File Updates](https://blog.gocept.com/2013/07/15/reliable-file-updates-with-python/) | **Article technique d√©taill√©** sur le pattern write-tempfile-fsync-rename. Explique POURQUOI chaque √©tape est n√©cessaire. |
| [Python os.fsync (zetcode)](https://zetcode.com/python/os-fsync/) | **Guide pratique fsync** avec exemples et explications sur les buffers OS. |
| [Python.org - Atomic Write Discussion](https://discuss.python.org/t/adding-atomicwrite-in-stdlib/11899) | **Discussion officielle** sur l'ajout d'atomic write en stdlib, montre que c'est un besoin reconnu. |

#### ‚ùå Sources Non Retenues

| Source | Raison de Rejet |
|--------|-----------------|
| [atomicwrites docs](https://python-atomicwrites.readthedocs.io/en/latest/) | **Maintenance inactive** depuis 2+ ans. Le pattern est bon mais la lib elle-m√™me est √† √©viter. |
| [Snyk - atomicwrites health](https://snyk.io/advisor/python/atomicwrites) | **Confirme le probl√®me** : projet consid√©r√© discontinued. |
| [ActiveState Recipe 579097](https://code.activestate.com/recipes/579097-safely-and-atomically-write-to-a-file/) | **Code dat√© (2016)**, Python 2 compatible, pas les meilleures pratiques actuelles. |
| [bugs.python.org/issue8828](https://bugs.python.org/issue8828) | **Discussion historique** (2010), d√©pass√©e par `os.replace()` en Python 3.3+. |

### üéØ Bonnes Pratiques SOTA 2025

1. **Utiliser une lib TOML** : `tomli-w` pour √©criture, `tomllib` (3.11+) ou `tomli` pour lecture
2. **Atomic write pattern** : tempfile ‚Üí write ‚Üí fsync ‚Üí rename
3. **os.replace()** : Atomique et cross-platform depuis Python 3.3
4. **Feedback utilisateur** : Ne pas retourner un bool√©en silencieux, lever une exception ou logger
5. **Validation avant √©criture** : V√©rifier que le TOML g√©n√©r√© est valide

### üìà Rem√©diation Graduelle

#### Niveau 1 - Lib TOML + Atomic Write Basique (30 min) ‚úÖ ESSENTIEL
```python
# AVANT (config.py L125-167) - Mauvais
def save_config(config: dict, path: Path) -> bool:
    try:
        with open(path, "w") as f:
            f.write("[general]\n")
            f.write(f'db_path = "{config["db_path"]}"\n')  # Pas d'√©chappement !
        return True
    except Exception:
        return False  # Silencieux !

# APR√àS - Bon
import tomli_w
import tempfile
import os

def save_config(config: dict, path: Path) -> None:
    """Sauvegarde la config de mani√®re atomique.

    Raises:
        OSError: Si l'√©criture √©choue
        TypeError: Si la config contient des types non s√©rialisables
    """
    # S√©rialiser via tomli-w (g√®re l'√©chappement)
    toml_content = tomli_w.dumps(config)

    # √âcriture atomique : tempfile + rename
    path = Path(path)
    path.parent.mkdir(parents=True, exist_ok=True)

    # Cr√©er fichier temp dans le m√™me r√©pertoire (m√™me filesystem)
    fd, tmp_path = tempfile.mkstemp(
        dir=path.parent,
        prefix=".config_",
        suffix=".tmp"
    )
    try:
        with os.fdopen(fd, 'w') as f:
            f.write(toml_content)
        # Atomic rename (cross-platform depuis Python 3.3)
        os.replace(tmp_path, path)
    except:
        # Cleanup en cas d'erreur
        os.unlink(tmp_path)
        raise
```

#### Niveau 2 - fsync + Feedback Utilisateur (1h) üëç RECOMMAND√â
```python
import tomli_w
import tempfile
import os
from pathlib import Path

def save_config_atomic(config: dict, path: Path) -> None:
    """Sauvegarde la config avec garanties de durabilit√©.

    Pattern: write ‚Üí flush ‚Üí fsync ‚Üí rename ‚Üí fsync dir
    Garantit que les donn√©es sont sur disque m√™me en cas de crash.
    """
    path = Path(path)
    path.parent.mkdir(parents=True, exist_ok=True)

    # S√©rialiser via tomli-w
    try:
        toml_content = tomli_w.dumps(config)
    except TypeError as e:
        raise ValueError(f"Config non s√©rialisable: {e}") from e

    # Cr√©er fichier temp dans le m√™me r√©pertoire
    fd, tmp_path = tempfile.mkstemp(
        dir=path.parent,
        prefix=".config_",
        suffix=".tmp"
    )
    tmp_path = Path(tmp_path)

    try:
        # √âcrire et sync le contenu
        with os.fdopen(fd, 'w') as f:
            f.write(toml_content)
            f.flush()
            os.fsync(f.fileno())

        # Atomic rename
        os.replace(tmp_path, path)

        # Sync le r√©pertoire parent (pour que le rename soit durable)
        dir_fd = os.open(path.parent, os.O_RDONLY | os.O_DIRECTORY)
        try:
            os.fsync(dir_fd)
        finally:
            os.close(dir_fd)

    except Exception as e:
        # Cleanup
        tmp_path.unlink(missing_ok=True)
        raise OSError(f"√âchec sauvegarde config: {e}") from e


# Usage avec feedback Typer
def cmd_set_config(key: str, value: str):
    """Commande CLI pour modifier la config."""
    try:
        config = load_config()
        config[key] = value
        save_config_atomic(config, get_config_path())
        typer.echo(f"‚úÖ Config mise √† jour: {key}={value}")
    except OSError as e:
        typer.echo(f"‚ùå Erreur: {e}", err=True)
        typer.echo("   V√©rifiez les permissions et l'espace disque", err=True)
        raise typer.Exit(1)
```

#### Niveau 3 - File Locking (Demi-journ√©e) ‚ö†Ô∏è OVERKILL
```python
import fcntl  # Unix only
from contextlib import contextmanager

@contextmanager
def locked_config(path: Path, mode: str = 'r'):
    """Context manager avec verrou exclusif sur la config.

    ATTENTION: Complexit√© √©lev√©e, probl√®mes potentiels :
    - fcntl ne fonctionne pas sur NFS/SMB
    - Pas portable Windows
    - Deadlocks possibles si mal utilis√©
    """
    path = Path(path)
    lock_path = path.with_suffix('.lock')

    with open(lock_path, 'w') as lock_file:
        fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX)
        try:
            with open(path, mode) as f:
                yield f
        finally:
            fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)

# Ou avec portalocker (cross-platform mais d√©pendance suppl√©mentaire)
# import portalocker
# with portalocker.Lock(path, 'w', timeout=5) as f:
#     f.write(content)
```

**Pourquoi c'est overkill :** Rekall est une CLI mono-utilisateur. Les acc√®s concurrents au m√™me fichier config sont quasi-impossibles. Le pattern atomic write (Niveau 2) prot√®ge d√©j√† contre les corruptions par crash.

---

## 14. Durcissement des Archives et Imports

### üî¥ Probl√©matique Identifi√©e

> **[MOYENNE] Chargement d'archives sans limites ni validation**
> - Lecture ZIP/JSON sans limite de taille ‚Üí risque OOM
> - Pas de v√©rification du ratio de compression ‚Üí vuln√©rable aux zip bombs
> - Aucune validation des champs JSON (taille contenu, nombre de tags)
> - Fichier concern√©: `archive.py:250-319`

### üìñ Sources Consult√©es

#### ‚úÖ Sources Retenues

| Source | Raison de R√©tention |
|--------|---------------------|
| [CVE-2024-0450 (Snyk)](https://security.snyk.io/vuln/SNYK-UNMANAGED-PYTHON-7924823) | **CVE r√©cent (2024)** sur zipfile Python, montre que les zip bombs restent un vecteur d'attaque actif. |
| [Python zipfile docs](https://docs.python.org/3/library/zipfile.html) | **Documentation officielle** avec avertissement sur les decompression bombs. |
| [AWS CodeGuru - Zip Bomb](https://docs.aws.amazon.com/codeguru/detector-library/python/zip-bomb-attack/) | **Recommandations AWS** pour la d√©tection et mitigation des zip bombs en Python. |
| [sunzip (GitHub)](https://github.com/twbgc/sunzip) | **Outil de r√©f√©rence** pour extraction s√©curis√©e, documente les strat√©gies de d√©fense (ratio, nested zips, limits). |
| [Pydantic - Field Constraints](https://docs.pydantic.dev/latest/concepts/fields/) | **Documentation officielle** pour les contraintes `max_length`, `min_items`, `max_items` sur les champs. |
| [bugs.python.org/issue36462](https://bugs.python.org/issue36462) | **CVE-2019-9674** - Discussion historique montrant que CPython ne corrigera pas le probl√®me c√¥t√© lib. |

#### ‚ùå Sources Non Retenues

| Source | Raison de Rejet |
|--------|-----------------|
| [bugs.python.org/issue39341](https://bugs.python.org/issue39341) | **Issue ferm√©e** avec conclusion "won't fix", pas de solution propos√©e c√¥t√© Python. |
| [Pillow #515](https://github.com/python-pillow/Pillow/issues/515) | **Sp√©cifique aux images** (decompression bomb pour images), pas applicable aux ZIP g√©n√©riques. |
| [pypi/warehouse #10504](https://github.com/pypi/warehouse/issues/10504) | **Contexte PyPI** sp√©cifique, solution trop complexe pour notre cas. |
| [python-security.readthedocs.io](https://python-security.readthedocs.io/security.html) | **Page g√©n√©rale** sans d√©tails sp√©cifiques sur les zip bombs. |

### üéØ Bonnes Pratiques SOTA 2025

1. **Limite de taille fichier** : V√©rifier `stat.st_size` avant ouverture
2. **Limite de taille d√©compress√©e** : Calculer taille totale avant extraction
3. **Ratio de compression** : Rejeter si ratio > 10-100x (zip bombs typiques = 1000x+)
4. **Validation JSON** : Pydantic avec contraintes `max_length`, `max_items`
5. **Timeout/quotas** : Pour sources non fiables, limiter ressources du processus

### üìà Rem√©diation Graduelle

#### Niveau 1 - Limites de Taille Basiques (30 min) ‚úÖ ESSENTIEL
```python
import os
from pathlib import Path
from zipfile import ZipFile

# Constantes de s√©curit√©
MAX_ARCHIVE_SIZE = 50 * 1024 * 1024  # 50 Mo max pour le fichier .rekall
MAX_DECOMPRESSED_SIZE = 200 * 1024 * 1024  # 200 Mo max d√©compress√©
MAX_ENTRIES = 10000  # Nombre max d'entr√©es dans l'archive

class ArchiveSecurityError(Exception):
    """Erreur de s√©curit√© lors du chargement d'archive."""
    pass

def load_archive_safe(path: Path) -> dict:
    """Charge une archive .rekall avec v√©rifications de s√©curit√©."""
    path = Path(path)

    # 1. V√©rifier la taille du fichier avant ouverture
    file_size = path.stat().st_size
    if file_size > MAX_ARCHIVE_SIZE:
        raise ArchiveSecurityError(
            f"Archive trop volumineuse: {file_size / 1024 / 1024:.1f} Mo "
            f"(max: {MAX_ARCHIVE_SIZE / 1024 / 1024:.0f} Mo)"
        )

    with ZipFile(path, 'r') as zf:
        # 2. V√©rifier le nombre d'entr√©es
        if len(zf.namelist()) > MAX_ENTRIES:
            raise ArchiveSecurityError(
                f"Trop d'entr√©es: {len(zf.namelist())} (max: {MAX_ENTRIES})"
            )

        # 3. V√©rifier la taille totale d√©compress√©e
        total_size = sum(info.file_size for info in zf.infolist())
        if total_size > MAX_DECOMPRESSED_SIZE:
            raise ArchiveSecurityError(
                f"Taille d√©compress√©e excessive: {total_size / 1024 / 1024:.1f} Mo "
                f"(max: {MAX_DECOMPRESSED_SIZE / 1024 / 1024:.0f} Mo)"
            )

        # 4. Lire les donn√©es
        data = zf.read('data.json')
        return json.loads(data)
```

#### Niveau 2 - Validation Champs + Ratio Compression (1-2h) üëç RECOMMAND√â
```python
from pydantic import BaseModel, Field, field_validator
from typing import List, Optional
import json

# Constantes de validation
MAX_CONTENT_SIZE = 1 * 1024 * 1024  # 1 Mo max par entr√©e
MAX_TAGS = 50  # 50 tags max par entr√©e
MAX_TAG_LENGTH = 100  # 100 chars max par tag
MAX_COMPRESSION_RATIO = 100  # Ratio max (100:1)

class EntryModel(BaseModel):
    """Mod√®le Pydantic pour valider les entr√©es import√©es."""
    id: str = Field(max_length=36)  # UUID
    title: str = Field(max_length=500)
    content: str = Field(max_length=MAX_CONTENT_SIZE)
    tags: List[str] = Field(default_factory=list, max_length=MAX_TAGS)
    created_at: str
    updated_at: Optional[str] = None

    @field_validator('tags')
    @classmethod
    def validate_tags(cls, tags: List[str]) -> List[str]:
        for tag in tags:
            if len(tag) > MAX_TAG_LENGTH:
                raise ValueError(f"Tag trop long: {len(tag)} chars (max: {MAX_TAG_LENGTH})")
        return tags

def check_compression_ratio(zf: ZipFile, compressed_size: int) -> None:
    """V√©rifie le ratio de compression pour d√©tecter les zip bombs."""
    total_uncompressed = sum(info.file_size for info in zf.infolist())

    if compressed_size > 0:
        ratio = total_uncompressed / compressed_size
        if ratio > MAX_COMPRESSION_RATIO:
            raise ArchiveSecurityError(
                f"Ratio de compression suspect: {ratio:.0f}:1 "
                f"(max: {MAX_COMPRESSION_RATIO}:1) - possible zip bomb"
            )

def load_archive_validated(path: Path) -> List[EntryModel]:
    """Charge et valide une archive .rekall."""
    path = Path(path)
    file_size = path.stat().st_size

    # V√©rifications de base (Niveau 1)
    if file_size > MAX_ARCHIVE_SIZE:
        raise ArchiveSecurityError(f"Archive trop volumineuse")

    with ZipFile(path, 'r') as zf:
        # V√©rifier ratio de compression
        check_compression_ratio(zf, file_size)

        # Lire et parser JSON
        raw_data = zf.read('data.json')
        data = json.loads(raw_data)

        # Valider chaque entr√©e avec Pydantic
        entries = []
        for i, item in enumerate(data.get('entries', [])):
            try:
                entry = EntryModel(**item)
                entries.append(entry)
            except Exception as e:
                raise ArchiveSecurityError(
                    f"Entr√©e {i} invalide: {e}"
                ) from e

        return entries
```

#### Niveau 3 - Sandbox avec Quotas Ressources (Demi-journ√©e) üü° OPTIONNEL
```python
import resource
import signal
from multiprocessing import Process, Queue
from typing import Any

# Limites de ressources
MEMORY_LIMIT = 256 * 1024 * 1024  # 256 Mo RAM max
CPU_TIME_LIMIT = 30  # 30 secondes max
FILE_SIZE_LIMIT = 100 * 1024 * 1024  # 100 Mo fichiers temp max

class ResourceLimitExceeded(Exception):
    """D√©passement des limites de ressources."""
    pass

def _limited_loader(path: str, queue: Queue) -> None:
    """Worker avec limites de ressources (ex√©cut√© dans subprocess)."""
    # Appliquer les limites
    resource.setrlimit(resource.RLIMIT_AS, (MEMORY_LIMIT, MEMORY_LIMIT))
    resource.setrlimit(resource.RLIMIT_CPU, (CPU_TIME_LIMIT, CPU_TIME_LIMIT))
    resource.setrlimit(resource.RLIMIT_FSIZE, (FILE_SIZE_LIMIT, FILE_SIZE_LIMIT))

    try:
        result = load_archive_validated(Path(path))
        queue.put(('success', result))
    except Exception as e:
        queue.put(('error', str(e)))

def load_archive_sandboxed(path: Path, timeout: int = 60) -> List[EntryModel]:
    """Charge une archive dans un processus isol√© avec limites.

    Utile si les archives proviennent de sources non fiables.
    """
    queue = Queue()
    process = Process(target=_limited_loader, args=(str(path), queue))
    process.start()
    process.join(timeout=timeout)

    if process.is_alive():
        process.terminate()
        process.join()
        raise ResourceLimitExceeded(f"Timeout apr√®s {timeout}s")

    if queue.empty():
        raise ResourceLimitExceeded("Process tu√© (probablement OOM)")

    status, result = queue.get()
    if status == 'error':
        raise ArchiveSecurityError(result)

    return result
```

**Quand c'est utile :** Si Rekall accepte des archives de sources externes (import depuis le web, partage entre utilisateurs). Pour usage personnel local, les Niveaux 1-2 suffisent amplement.

### Points Positifs Identifi√©s

L'audit a relev√© que le syst√®me de checksum existe d√©j√†, mais ne prot√®ge pas contre les zip bombs :

```python
# D√©j√† pr√©sent - √Ä conserver mais insuffisant seul
def verify_checksum(path: Path, expected: str) -> bool:
    """V√©rifie l'int√©grit√© de l'archive."""
    # Le checksum valide l'int√©grit√©, pas la s√©curit√© !
    # Une zip bomb a un checksum valide.
    ...
```

**Recommandation :** Conserver la v√©rification de checksum (int√©grit√©) ET ajouter les v√©rifications de taille/ratio (s√©curit√©).

---

## 15. D√©tection et Correction des Contributions IA

### üî¥ Probl√©matique Identifi√©e

> **[MOYENNE] Travers typiques du code g√©n√©r√© par IA**
> - Fonctionnalit√©s annonc√©es mais non impl√©ment√©es (commande `similar` avec embeddings)
> - Cha√Ænes/placeholders non r√©solus (TODO espagnol dans i18n)
> - Interpolations f-strings oubli√©es (`{config.embeddings_provider}` affich√© litt√©ralement)
> - Lint actuel (E/F/I/W) ne d√©tecte pas ces d√©rives
> - Fichiers concern√©s: `cli.py:1188-1216`, `i18n.py:607-1104`, `cli.py:1197-1203`, `pyproject.toml:38-57`

### üìñ Sources Consult√©es

#### ‚úÖ Sources Retenues

| Source | Raison de R√©tention |
|--------|---------------------|
| [Ruff Rules Documentation](https://docs.astral.sh/ruff/rules/) | **R√©f√©rence officielle** : liste exhaustive des 800+ r√®gles Ruff, incluant ANN (annotations), B (bugbear), N (naming), PL (pylint). |
| [BetterStack - Ruff Explained](https://betterstack.com/community/guides/scaling-python/ruff-explained/) | **Guide complet 2025** avec exemples de configuration pyproject.toml et bonnes pratiques d'activation progressive des r√®gles. |
| [Pylint W1309 - f-string-without-interpolation](https://pylint.readthedocs.io/en/stable/user_guide/messages/warning/f-string-without-interpolation.html) | **Documentation officielle** de la r√®gle d√©tectant les f-strings sans interpolation (pattern inverse du probl√®me). |
| [Pylint Issue #2507 - Detect missing f-prefix](https://github.com/PyCQA/pylint/issues/2507) | **Discussion technique** sur la d√©tection des strings avec syntax `{var}` mais sans pr√©fixe f. Montre que le probl√®me est reconnu. |
| [Sloppylint - AI Slop Detector](https://github.com/rsionnach/sloppylint) | **Outil sp√©cialis√© 2025** pour d√©tecter les patterns IA : placeholders, imports hallucin√©s, cross-language leakage, hedging comments. |
| [Qodo - Code Quality 2025](https://www.qodo.ai/blog/code-quality/) | **Guide moderne** sur la qualit√© du code avec contributions IA, incluant strat√©gies de revue et outils. |
| [PEP 8 - Style Guide](https://peps.python.org/pep-0008/) | **Standard officiel** Python pour les conventions de nommage et de style. R√©f√©rence incontournable. |
| [flake8-todos (orsinium)](https://github.com/orsinium-labs/flake8-todos) | **Plugin sp√©cialis√©** pour linter les commentaires TODO : format, auteur, lien issue. R√®gles T001-T005. |
| [JetBrains - Coding Guidelines for AI Agents](https://blog.jetbrains.com/idea/2025/05/coding-guidelines-for-your-ai-agents/) | **Guide pratique** pour cr√©er des guidelines compatibles avec les agents IA. |

#### ‚ùå Sources Non Retenues

| Source | Raison de Rejet |
|--------|-----------------|
| [xugj520 - Detect AI Code](https://www.xugj520.cn/en/archives/detect-ai-generated-python-code.html) | **Site peu fiable**, contenu probablement traduit automatiquement, pas de sources techniques v√©rifiables. |
| [Musely AI Code Checker](https://musely.ai/tools/ai-code-checker) | **Outil commercial** sans documentation technique ouverte, approche bo√Æte noire. |
| [Medium - Comment Checker](https://medium.com/@adrien.riaux/comment-checker-a-python-pre-commit-3b21dcaf7194) | **Article ancien** (2021), pr√©-Ruff, sugg√®re des outils obsol√®tes. |
| [deepaksood619 - Static Analysis](https://deepaksood619.github.io/python/documentation/27-development-tools/static-code-analysis/) | **Notes personnelles** sans structure ni maintenance, liens cass√©s. |
| [Gatlen Culp - Pre-commit 2025](https://gatlenculp.medium.com/effortless-code-quality-the-ultimate-pre-commit-hooks-guide-for-2025-57ca501d9835) | **Medium paywall**, contenu inaccessible pour v√©rification. |

### üéØ Bonnes Pratiques SOTA 2025

1. **Lint √©largi** : Activer Ruff avec r√®gles ANN, B, N, PL en plus de E/F/I/W
2. **D√©tection f-strings** : Pylint W1309 ou recherche manuelle `{.*}` sans pr√©fixe f
3. **Audit TODO/placeholders** : flake8-todos ou grep pour TODO non format√©s
4. **Conventions explicites** : Guide de style document√© avec PEP 8 + patterns projet
5. **Revue narrative** : V√©rifier coh√©rence entre docs, messages CLI et fonctionnalit√©s r√©elles
6. **Traitement des "promesses fant√¥mes"** : Masquer ou impl√©menter les features annonc√©es

### üìà Rem√©diation Graduelle

#### Niveau 1 - Ruff √âlargi + Fix F-Strings (1h) ‚úÖ ESSENTIEL
```toml
# pyproject.toml - Configuration Ruff √©tendue
[tool.ruff]
line-length = 88
target-version = "py311"

[tool.ruff.lint]
select = [
    "E",    # Errors (pycodestyle)
    "F",    # Pyflakes
    "W",    # Warnings
    "I",    # isort
    "B",    # flake8-bugbear (bugs courants)
    "N",    # pep8-naming (conventions nommage)
    "UP",   # pyupgrade (Python moderne)
    "PL",   # Pylint (analyse approfondie)
    "ANN",  # flake8-annotations (types)
    "S",    # flake8-bandit (s√©curit√©)
]

# Ignores raisonnables pour √©viter le bruit
ignore = [
    "E501",   # Line too long (g√©r√© par formatter)
    "ANN101", # Missing type annotation for self
    "ANN102", # Missing type annotation for cls
    "ANN401", # Dynamically typed expressions (Any)
    "PLR0913", # Too many arguments (parfois n√©cessaire)
]

[tool.ruff.lint.per-file-ignores]
"tests/*" = ["ANN", "S101"]  # Tests: pas de types, assert OK
"__init__.py" = ["F401"]      # Unused imports OK pour re-export
```

```python
# AVANT - cli.py:1197-1203 (f-string oubli√©e)
typer.echo("Using embeddings provider: {config.embeddings_provider}")

# APR√àS - Corrig√©
typer.echo(f"Using embeddings provider: {config.embeddings_provider}")
```

```bash
# Script de d√©tection des f-strings manquantes
grep -rn '"\{[a-zA-Z_][a-zA-Z0-9_.]*\}"' rekall/ --include="*.py" | \
  grep -v "^[^:]*:[^:]*:.*f\""
# Retourne les lignes avec {var} dans des strings non-f
```

#### Niveau 2 - Audit TODO + Guide de Style (2-3h) üëç RECOMMAND√â
```toml
# pyproject.toml - Ajout flake8-todos via Ruff
[tool.ruff.lint]
extend-select = ["TD"]  # flake8-todos rules

# TD001: Invalid TODO tag
# TD002: Missing author in TODO
# TD003: Missing link in TODO
# TD004: Missing colon in TODO
# TD005: Missing description in TODO
```

```python
# Script d'audit des TODO/placeholders non r√©solus
import re
from pathlib import Path

SUSPICIOUS_PATTERNS = [
    r'#\s*TODO(?!:)',           # TODO sans format standard
    r'#\s*FIXME',               # FIXME non r√©solu
    r'pass\s*#.*TODO',          # pass avec TODO = non impl√©ment√©
    r'raise NotImplementedError', # Placeholder explicite
    r'\.\.\..*#.*implement',    # Ellipsis avec commentaire
]

def audit_placeholders(directory: Path):
    """Scanne les placeholders suspects."""
    issues = []
    for py_file in directory.rglob("*.py"):
        content = py_file.read_text()
        for i, line in enumerate(content.splitlines(), 1):
            for pattern in SUSPICIOUS_PATTERNS:
                if re.search(pattern, line, re.IGNORECASE):
                    issues.append(f"{py_file}:{i}: {line.strip()}")
    return issues

# Usage
for issue in audit_placeholders(Path("rekall")):
    print(issue)
```

```markdown
# STYLE_GUIDE.md - Conventions du projet Rekall

## Conventions de Nommage (PEP 8)
- **Fonctions/Variables**: `snake_case` (ex: `get_entry_by_id`)
- **Classes**: `PascalCase` (ex: `ArchiveManager`)
- **Constantes**: `UPPER_SNAKE_CASE` (ex: `MAX_ARCHIVE_SIZE`)
- **Priv√©**: Pr√©fixe `_` (ex: `_internal_helper`)

## Patterns Projet
- **Commandes CLI**: Un fichier par domaine dans `commands/`
- **S√©rialisation**: Utiliser `rekall/serializers.py` exclusivement
- **Configuration**: Via `config.py`, jamais de hardcode

## TODO Format Standard
```python
# TODO(username): Description courte - Issue #123
```

## Fonctionnalit√©s Non Impl√©ment√©es
- Masquer dans l'UI jusqu'√† impl√©mentation compl√®te
- Lever `NotImplementedError` avec message explicite
- Documenter dans ROADMAP.md, pas dans le code
```

#### Niveau 3 - Sloppylint + Revue Narrative (Demi-journ√©e) üü° OPTIONNEL
```bash
# Installation de sloppylint (outil exp√©rimental)
pip install sloppylint

# Analyse du projet
sloppylint rekall/

# Output typique:
# rekall/cli.py:1200 - PLACEHOLDER: pass statement with TODO comment
# rekall/cli.py:1210 - HEDGING: "should work" comment suggests uncertainty
# rekall/i18n.py:650 - PLACEHOLDER: "TODO" in user-visible string
```

```python
# Script de revue narrative : coh√©rence docs/fonctionnalit√©s
import ast
from pathlib import Path

def extract_cli_commands(cli_file: Path) -> set:
    """Extrait les noms des commandes CLI d√©finies."""
    tree = ast.parse(cli_file.read_text())
    commands = set()
    for node in ast.walk(tree):
        if isinstance(node, ast.FunctionDef):
            for decorator in node.decorator_list:
                if isinstance(decorator, ast.Call):
                    if hasattr(decorator.func, 'attr'):
                        if decorator.func.attr == 'command':
                            commands.add(node.name)
    return commands

def extract_documented_features(readme: Path) -> set:
    """Extrait les features mentionn√©es dans la doc."""
    content = readme.read_text().lower()
    # Patterns de features typiques
    features = set()
    import re
    for match in re.findall(r'`rekall (\w+)`', content):
        features.add(match)
    return features

# Audit de coh√©rence
cli_commands = extract_cli_commands(Path("rekall/cli.py"))
doc_features = extract_documented_features(Path("README.md"))

ghost_features = doc_features - cli_commands
print(f"‚ö†Ô∏è Features document√©es mais non impl√©ment√©es: {ghost_features}")

hidden_features = cli_commands - doc_features
print(f"‚ÑπÔ∏è Commandes non document√©es: {hidden_features}")
```

**Quand c'est utile :** Si le projet a plusieurs contributeurs (humains ou IA) ou si tu reprends un projet g√©n√©r√© par IA. Pour un projet solo avec historique connu, les Niveaux 1-2 suffisent.

### Cas Sp√©cifiques Identifi√©s dans Rekall

#### 1. Commande `similar` - Fonctionnalit√© Fant√¥me
```python
# cli.py:1188-1216 - AVANT
@app.command("similar")
def similar(query: str):
    """Find similar entries using embeddings."""
    typer.echo("Using embeddings provider: {config.embeddings_provider}")
    # TODO: Implement actual embedding search
    pass

# APR√àS - Option A : Masquer jusqu'√† impl√©mentation
# Supprimer la commande et ajouter dans ROADMAP.md

# APR√àS - Option B : Message explicite
@app.command("similar")
def similar(query: str):
    """Find similar entries using embeddings (coming soon)."""
    typer.echo("‚ö†Ô∏è Cette fonctionnalit√© n'est pas encore impl√©ment√©e.")
    typer.echo("Voir: https://github.com/user/rekall/issues/XX")
    raise typer.Exit(1)
```

#### 2. Traductions Espagnol - TODO Non R√©solu
```python
# i18n.py:607-1104 - Fichier avec "TODO" dans les traductions
TRANSLATIONS = {
    "es": {
        "search_prompt": "TODO",  # ‚Üê Visible dans l'UI !
        "no_results": "TODO",
        # ...
    }
}

# Solution : Fallback sur anglais si TODO
def get_translation(key: str, lang: str = "en") -> str:
    text = TRANSLATIONS.get(lang, {}).get(key, "")
    if text == "TODO" or not text:
        return TRANSLATIONS["en"].get(key, key)
    return text
```

---

## 16. Roadmap de Mise en ≈íuvre (R√©vis√©e)

> ‚ö†Ô∏è **Cette roadmap a √©t√© ajust√©e** pour refl√©ter l'analyse de pertinence ci-dessus.
> Les items marqu√©s ~~barr√©s~~ sont de l'over-engineering pour le contexte Rekall.

### üìÖ Planning Prioris√© (Pragmatique)

| Phase | Dur√©e | Items | Priorit√© |
|-------|-------|-------|----------|
| **Imm√©diat** | Semaine 1 | CI/CD Niveau 1, permissions 600, uv.lock, Ruff basique, DRY serializers, Vulture CI, Exceptions cibl√©es, tomli-w, Limites archives, **Ruff √©largi IA (ANN,B,N,PL)**, **Fix f-strings** | üî¥ Critique |
| **Court terme** | Semaines 2-3 | Pydantic validators, CI lockfile, Ruff √©tendu, Safety, Module serializers, Commandes int√©grations, Rich feedback, Atomic write+fsync, Validation ZIP ratio, **Audit TODO**, **Guide de style** | üü† Haute |
| **Optionnel** | Selon besoins | SQLCipher, keyring, d√©tection PII regex, CLI modulaire, Plugins dynamiques, Loguru/structlog, Sandbox archives, **Sloppylint**, **Revue narrative** | üü° Si n√©cessaire |
| ~~Long terme~~ | ~~Mois 2-3~~ | ~~Clean Architecture, audit logs, Repository Pattern, File locking fcntl, AI detection ML~~ | ‚ö†Ô∏è OVERKILL |

### üìã Checklist de Validation (R√©aliste)

#### ‚úÖ Phase Imm√©diate - Obligatoire (Score cible: B+)
- [ ] `.github/workflows/security.yml` avec pip-audit + Bandit
- [ ] `uv.lock` g√©n√©r√© et committ√©
- [ ] Ruff configur√© avec r√®gles `E`, `F`, `W`
- [ ] Permissions 600 sur le fichier DB (`secure_db_permissions()`)
- [ ] Requ√™tes SQL toutes param√©tr√©es (v√©rifier `?` placeholders)
- [ ] **DRY** : `entry_to_dict()` factoris√© dans `rekall/serializers.py`
- [ ] **Vulture** : Configuration dans `pyproject.toml` + whitelist
- [ ] **Exceptions cibl√©es** : Remplacer `except Exception` par types sp√©cifiques
- [ ] **tomli-w** : Utiliser lib TOML au lieu de manipulation manuelle
- [ ] **Limites archives** : `MAX_ARCHIVE_SIZE` + `MAX_DECOMPRESSED_SIZE`
- [ ] **Ruff √©largi IA** : Activer r√®gles ANN, B, N, PL *(Nouveau)*
- [ ] **Fix f-strings** : Corriger `{var}` sans pr√©fixe f (grep + correction) *(Nouveau)*

#### üëç Phase Court Terme - Recommand√©e (Score cible: A-)
- [ ] CI compl√®te : tests + lint + security + **Vulture**
- [ ] Pydantic validators pour `NoteInput` et `SearchQuery`
- [ ] Ruff √©tendu avec `I`, `B`, `S`, `UP`
- [ ] Safety ajout√© √† la CI
- [ ] Documentation RGPD basique dans README
- [ ] **Module serializers** : `rekall/serializers.py` avec Pydantic (optionnel)
- [ ] **Int√©grations expos√©es** : `rekall list-integrations` + `install-integration`
- [ ] **Rich error feedback** : Messages utilisateur avec Panel + suggestions
- [ ] **Atomic write + fsync** : Pattern tempfile ‚Üí fsync ‚Üí rename pour config.toml
- [ ] **Validation ZIP ratio** : D√©tection zip bombs (ratio > 100:1)
- [ ] **Audit TODO/placeholders** : Scanner et corriger les TODO non r√©solus *(Nouveau)*
- [ ] **Guide de style** : `STYLE_GUIDE.md` avec conventions PEP 8 + patterns projet *(Nouveau)*

#### üü° Phase Optionnelle - Selon Contexte
- [ ] SQLCipher : **Seulement si** donn√©es vraiment sensibles
- [ ] Keyring : **Seulement si** SQLCipher activ√©
- [ ] D√©tection PII regex : **Seulement si** exports fr√©quents
- [ ] Pre-commit hooks : **Seulement si** contributeurs externes
- [ ] Entit√©s extraites : **Seulement si** tests unitaires pouss√©s
- [ ] **CLI modulaire** : `rekall/commands/*.py` **Seulement si** cli.py d√©passe ~3k LOC
- [ ] **Plugins dynamiques** : Stevedore/entry points **Seulement si** plugins tiers pr√©vus
- [ ] **Structured logging** : Loguru/structlog **Seulement si** debug complexe requis
- [ ] **Sandbox extraction** : `resource.setrlimit()` **Seulement si** archives externes
- [ ] **Sloppylint** : D√©tection patterns IA **Seulement si** contributions multi-agents *(Nouveau)*
- [ ] **Revue narrative** : Audit coh√©rence docs/fonctionnalit√©s **Seulement si** √©quipe *(Nouveau)*

#### ‚ö†Ô∏è Items Retir√©s (Over-engineering)
Les items suivants √©taient dans la roadmap initiale mais sont **d√©conseill√©s** :

| Item retir√© | Raison |
|-------------|--------|
| ~~Semgrep + SARIF~~ | Bandit couvre 88% des vuln√©rabilit√©s Python, suffisant |
| ~~Sessions avec timeout~~ | Pattern web, non applicable √† une CLI |
| ~~Audit logs~~ | `.bash_history` suffit pour usage personnel |
| ~~Triggers SQL audit~~ | Complexit√© injustifi√©e pour <500 LOC |
| ~~Repository Pattern~~ | Un seul backend SQLite, YAGNI |
| ~~Use Cases + DI~~ | Architecture enterprise, inadapt√©e |
| ~~Migration chiffr√©e auto~~ | Chiffrer d√®s le d√©part si n√©cessaire |
| ~~SBOM~~ | Pour projets critiques uniquement |
| ~~File locking fcntl~~ | CLI mono-utilisateur, atomic write suffit *(Nouveau)* |

### üéØ Score R√©aliste Atteignable

| Phase | Effort | Score | Valeur ajout√©e |
|-------|--------|-------|----------------|
| Imm√©diat | ~2h | B+ | Protection CVE, reproductibilit√©, qualit√© code |
| Court terme | ~4h | A- | Validation robuste, s√©curit√© FTS, CI compl√®te |
| Total recommand√© | ~6h | **A-** | Excellent rapport effort/s√©curit√© |

**Note:** Viser A+ n√©cessiterait ~20h+ d'over-engineering pour un gain marginal.
Le score A- repr√©sente le **sweet spot** pour Rekall.

---

## üìö R√©f√©rences Compl√®tes

### Standards et Guides Officiels
- [OWASP Top 10:2025](https://owasp.org/Top10/2025/0x00_2025-Introduction/)
- [OWASP Input Validation Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Input_Validation_Cheat_Sheet.html)
- [PEP 751 - Python Lock File Format](https://peps.python.org/pep-0751/)

### Outils de S√©curit√©
- [pip-audit (PyPA)](https://github.com/pypa/pip-audit)
- [Safety CLI](https://github.com/pyupio/safety)
- [Bandit](https://github.com/PyCQA/bandit)
- [SQLCipher](https://www.zetetic.net/sqlcipher/)

### Biblioth√®ques Python
- [Pydantic Documentation](https://docs.pydantic.dev/)
- [keyring Documentation](https://keyring.readthedocs.io/)
- [sqlcipher3](https://github.com/coleifer/sqlcipher3)

### Qualit√© et Linting
- [Ruff Documentation](https://docs.astral.sh/ruff/)
- [uv Documentation](https://docs.astral.sh/uv/)
- [Vulture - Dead Code Finder](https://github.com/jendrikseipp/vulture)
- [deadcode Package](https://pypi.org/project/deadcode/)
- [Adam Johnson - Vulture Best Practices](https://adamj.eu/tech/2023/07/12/django-clean-up-unused-code-vulture/)

### Architecture et Patterns
- [Cosmic Python - Architecture Patterns](https://www.cosmicpython.com/)
- [Clean Architecture Python (glukhov.org)](https://www.glukhov.org/post/2025/11/python-design-patterns-for-clean-architecture/)
- [Stevedore - Plugin Management (OpenStack)](https://docs.openstack.org/stevedore/latest/)
- [Pluggy - pytest Plugin Framework](https://github.com/pytest-dev/pluggy)

### CLI et Structure de Code
- [Typer Documentation](https://typer.tiangolo.com/)
- [Typer add_typer() for Subcommands](https://typer.tiangolo.com/tutorial/subcommands/)
- [Real Python - DRY Principle](https://realpython.com/python-refactoring/)
- [Martin Fowler - Refactoring: Extract Method](https://refactoring.com/catalog/extractMethod.html)

### RGPD et PII
- [Alation - GDPR Best Practices 2025](https://www.alation.com/blog/gdpr-data-compliance-best-practices-2025/)
- [PII Masker (HydroXai)](https://github.com/HydroXai/pii-masker)

### Exception Handling et Logging (Nouveau)
- [PEP 760 - No More Bare Excepts](https://peps.python.org/pep-0760/)
- [Qodo - 6 Best Practices Python Exceptions](https://www.qodo.ai/blog/6-best-practices-for-python-exception-handling/)
- [Real Python - Diabolical Antipattern](https://realpython.com/the-most-diabolical-python-antipattern/)
- [Typer - Exceptions](https://typer.tiangolo.com/tutorial/exceptions/)
- [BetterStack - Loguru Guide](https://betterstack.com/community/guides/logging/loguru/)
- [Structlog - Logging Best Practices](https://www.structlog.org/en/stable/logging-best-practices.html)

### √âcriture Atomique et TOML (Nouveau)
- [Real Python - Python and TOML](https://realpython.com/python-toml/)
- [tomli-w (PyPI)](https://pypi.org/project/tomli-w/)
- [gocept - Reliable File Updates](https://blog.gocept.com/2013/07/15/reliable-file-updates-with-python/)
- [Python os.fsync (zetcode)](https://zetcode.com/python/os-fsync/)
- [Python.org - Atomic Write Discussion](https://discuss.python.org/t/adding-atomicwrite-in-stdlib/11899)

### S√©curit√© Archives et ZIP Bombs
- [CVE-2024-0450 (Snyk)](https://security.snyk.io/vuln/SNYK-UNMANAGED-PYTHON-7924823)
- [Python zipfile Documentation](https://docs.python.org/3/library/zipfile.html)
- [AWS CodeGuru - Zip Bomb Attack](https://docs.aws.amazon.com/codeguru/detector-library/python/zip-bomb-attack/)
- [sunzip - Secure Unzip (GitHub)](https://github.com/twbgc/sunzip)
- [CVE-2019-9674 Discussion](https://bugs.python.org/issue36462)

### Hygi√®ne Code IA et Conventions (Nouveau)
- [Ruff Rules Documentation](https://docs.astral.sh/ruff/rules/)
- [BetterStack - Ruff Explained](https://betterstack.com/community/guides/scaling-python/ruff-explained/)
- [Pylint W1309 - f-string-without-interpolation](https://pylint.readthedocs.io/en/stable/user_guide/messages/warning/f-string-without-interpolation.html)
- [Pylint Issue #2507 - Missing f-prefix Detection](https://github.com/PyCQA/pylint/issues/2507)
- [Sloppylint - AI Slop Detector](https://github.com/rsionnach/sloppylint)
- [flake8-todos (orsinium)](https://github.com/orsinium-labs/flake8-todos)
- [PEP 8 - Style Guide](https://peps.python.org/pep-0008/)
- [Qodo - Code Quality 2025](https://www.qodo.ai/blog/code-quality/)
- [JetBrains - Coding Guidelines for AI Agents](https://blog.jetbrains.com/idea/2025/05/coding-guidelines-for-your-ai-agents/)

---

*Document g√©n√©r√© le 2025-12-11*
*Bas√© sur l'audit de s√©curit√© Rekall*
